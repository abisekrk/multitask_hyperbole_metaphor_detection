{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Change the task_name to either Hyperbole or Metaphor\n",
        "task_name = \"Metaphor\"\n",
        "\n",
        "# Change the dataset name to to the csv file name in use\n",
        "dataset_name = \"new_combined\"\n",
        "\n",
        "# Change the model_name to one of the following names\n",
        "# BERT large    ----> bert-large-uncased\n",
        "# ALBERT large  ----> albert-xxlarge-v2\n",
        "# RoBERTa large ----> roberta-large\n",
        "model_name = \"bert-large-uncased\"\n",
        "\n",
        "seed_val = 42\n",
        "\n",
        "# Change the numbers in random_list for 3 runs of 10-fold cross-validation run\n",
        "random_list = [42,101,2020]\n",
        "\n",
        "# Change random_st variable for the 10-fold cross-validation run\n",
        "random_st = 42\n",
        "\n",
        "# Hyperparameters\n",
        "MAX_LEN=64\n",
        "batch_size = 16\n",
        "epochs = 10\n",
        "learning_rate = 1e-5"
      ],
      "metadata": {
        "id": "t0uoyAysh5z9"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers --quiet\n",
        "from transformers import *\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "from torch.nn import BCEWithLogitsLoss, BCELoss\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix, f1_score, accuracy_score\n",
        "\n",
        "import pickle\n",
        "from tqdm import tqdm, trange\n",
        "import tensorflow as tf\n",
        "\n",
        "from operator import itemgetter\n",
        "from statistics import mean, stdev\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJutXjh5iIU_",
        "outputId": "8e99736e-3a94-46dc-f148-09107b33595d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 5.3 MB 43.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 163 kB 58.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 48.8 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the seed value all over the place to make this reproducible.\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "metadata": {
        "id": "xqQ_ajLkkTFr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFmuovNM29LQ",
        "outputId": "595b6edb-204b-46f4-f403-8bc879a268f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU found at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found!')\n",
        "print('GPU found at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wY1A_Ynt3Spx",
        "outputId": "9abdc6d1-745c-46a4-d1cd-455a4770f77c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla T4\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(torch.cuda.get_device_name(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "yX_jgi_u3btE",
        "outputId": "537e8875-5665-44ca-a775-980528459719"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Sentence  Hyperbole  Metaphor\n",
              "0           Insolent boy, I'll slash you to ribbons!          1         1\n",
              "1  The level of discombobulation in the realm of ...          1         1\n",
              "2                           His eyes were very dark.          0         0\n",
              "3  It's been a long time since I found someone ni...          0         0\n",
              "4          Oh, you are soaked to the bone, monsieur.          1         1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-75c8cb80-6685-4cd0-8271-00072acadc59\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Hyperbole</th>\n",
              "      <th>Metaphor</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Insolent boy, I'll slash you to ribbons!</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The level of discombobulation in the realm of ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>His eyes were very dark.</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>It's been a long time since I found someone ni...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Oh, you are soaked to the bone, monsieur.</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-75c8cb80-6685-4cd0-8271-00072acadc59')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-75c8cb80-6685-4cd0-8271-00072acadc59 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-75c8cb80-6685-4cd0-8271-00072acadc59');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df = pd.read_csv(dataset_name+'.csv')\n",
        "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "df = df.dropna(axis=0).reset_index(drop=True)\n",
        "\n",
        "df[\"Hyperbole\"] = df[\"Hyperbole\"].astype(\"int\")\n",
        "df[\"Metaphor\"] = df[\"Metaphor\"].astype(\"int\")\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AACaTzoXDjiW",
        "outputId": "3b1d4c06-85ee-4b8c-e8c4-ee122c86c83b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label columns:  ['Hyperbole', 'Metaphor']\n"
          ]
        }
      ],
      "source": [
        "cols = df.columns\n",
        "label_cols = list(cols[1:])\n",
        "num_labels = len(label_cols)\n",
        "print('Label columns: ', label_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5xF7aiTbDjiW",
        "outputId": "9f002282-1e4b-44a2-e83b-bfb35314a9d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Sentence  Hyperbole  Metaphor  \\\n",
              "0           Insolent boy, I'll slash you to ribbons!          1         1   \n",
              "1  The level of discombobulation in the realm of ...          1         1   \n",
              "2                           His eyes were very dark.          0         0   \n",
              "3  It's been a long time since I found someone ni...          0         0   \n",
              "4          Oh, you are soaked to the bone, monsieur.          1         1   \n",
              "\n",
              "  one_hot_labels  \n",
              "0         [1, 1]  \n",
              "1         [1, 1]  \n",
              "2         [0, 0]  \n",
              "3         [0, 0]  \n",
              "4         [1, 1]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-648cc0d3-7def-4f19-a2b9-6ef062d6fb31\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Hyperbole</th>\n",
              "      <th>Metaphor</th>\n",
              "      <th>one_hot_labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Insolent boy, I'll slash you to ribbons!</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[1, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The level of discombobulation in the realm of ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[1, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>His eyes were very dark.</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>It's been a long time since I found someone ni...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Oh, you are soaked to the bone, monsieur.</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[1, 1]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-648cc0d3-7def-4f19-a2b9-6ef062d6fb31')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-648cc0d3-7def-4f19-a2b9-6ef062d6fb31 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-648cc0d3-7def-4f19-a2b9-6ef062d6fb31');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df['one_hot_labels'] = list(df[label_cols].values)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "NxyiuE-DDjiW",
        "outputId": "4a90078f-2df2-4861-fde9-3a7204955c80"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Sentence  Hyperbole  Metaphor  \\\n",
              "0           Insolent boy, I'll slash you to ribbons!          1         1   \n",
              "1  The level of discombobulation in the realm of ...          1         1   \n",
              "2                           His eyes were very dark.          0         0   \n",
              "3  It's been a long time since I found someone ni...          0         0   \n",
              "4          Oh, you are soaked to the bone, monsieur.          1         1   \n",
              "\n",
              "  one_hot_labels  new  \n",
              "0         [1, 1]    3  \n",
              "1         [1, 1]    3  \n",
              "2         [0, 0]    0  \n",
              "3         [0, 0]    0  \n",
              "4         [1, 1]    3  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dadf3c9c-93d3-4e43-a569-c8f1e412a964\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Hyperbole</th>\n",
              "      <th>Metaphor</th>\n",
              "      <th>one_hot_labels</th>\n",
              "      <th>new</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Insolent boy, I'll slash you to ribbons!</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[1, 1]</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The level of discombobulation in the realm of ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[1, 1]</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>His eyes were very dark.</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 0]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>It's been a long time since I found someone ni...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 0]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Oh, you are soaked to the bone, monsieur.</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[1, 1]</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dadf3c9c-93d3-4e43-a569-c8f1e412a964')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dadf3c9c-93d3-4e43-a569-c8f1e412a964 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dadf3c9c-93d3-4e43-a569-c8f1e412a964');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "conditions = [\n",
        "    (df[\"Hyperbole\"]==0) & (df[\"Metaphor\"]==0),\n",
        "    (df[\"Hyperbole\"]==0) & (df[\"Metaphor\"]==1),\n",
        "    (df[\"Hyperbole\"]==1) & (df[\"Metaphor\"]==0),\n",
        "    (df[\"Hyperbole\"]==1) & (df[\"Metaphor\"]==1)\n",
        "]\n",
        "choices = [0,1,2,3]\n",
        "\n",
        "df[\"new\"] = np.select(conditions, choices)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oB6pea1DjiX",
        "outputId": "321aef7e-c4d4-4bc9-b137-c40674fa4fc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    796\n",
            "1    622\n",
            "Name: Metaphor, dtype: int64\n",
            "1    709\n",
            "0    709\n",
            "Name: Hyperbole, dtype: int64\n",
            "0    602\n",
            "3    515\n",
            "2    194\n",
            "1    107\n",
            "Name: new, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(df[\"Metaphor\"].value_counts())\n",
        "print(df[\"Hyperbole\"].value_counts())\n",
        "print(df.new.value_counts())\n",
        "\n",
        "y= df[\"new\"].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "kfP7gguLDjiX"
      },
      "outputs": [],
      "source": [
        "labels = list(df.one_hot_labels.values)\n",
        "comments = list(df.Sentence.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "L6_U2KdtDjiY",
        "outputId": "8969329d-b7fe-4822-b798-d41543be2cc4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            sentence  Hyperbole  target  \\\n",
              "0           Insolent boy, I'll slash you to ribbons!          1       1   \n",
              "1  The level of discombobulation in the realm of ...          1       1   \n",
              "2                           His eyes were very dark.          0       0   \n",
              "3  It's been a long time since I found someone ni...          0       0   \n",
              "4          Oh, you are soaked to the bone, monsieur.          1       1   \n",
              "\n",
              "  one_hot_labels  new  \n",
              "0         [1, 1]    3  \n",
              "1         [1, 1]    3  \n",
              "2         [0, 0]    0  \n",
              "3         [0, 0]    0  \n",
              "4         [1, 1]    3  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bad1bb88-a2f1-45ed-87ee-654af626073e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>Hyperbole</th>\n",
              "      <th>target</th>\n",
              "      <th>one_hot_labels</th>\n",
              "      <th>new</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Insolent boy, I'll slash you to ribbons!</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[1, 1]</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The level of discombobulation in the realm of ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[1, 1]</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>His eyes were very dark.</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 0]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>It's been a long time since I found someone ni...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 0]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Oh, you are soaked to the bone, monsieur.</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[1, 1]</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bad1bb88-a2f1-45ed-87ee-654af626073e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bad1bb88-a2f1-45ed-87ee-654af626073e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bad1bb88-a2f1-45ed-87ee-654af626073e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "df.rename(columns = {\"Sentence\":\"sentence\", task_name:\"target\"}, inplace=True)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "-pJXMG8M4H0M"
      },
      "outputs": [],
      "source": [
        "labels = df.target.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "cb478d734ab74ac7b5537befb46c9802",
            "0d0be20cf7984e5cb864c4c8d75e5b2d",
            "71e516ac54b948ac8328ef5d9f63d9eb",
            "fa9010a2fb964530be3cf88361ca0430",
            "c112c82ccff748f98bf6d5c197188990",
            "1713c61d5be64b239d6e47b36b6f9d26",
            "8acbede6c3dc4d5dada8e8a914ffd827",
            "5a1a73d051614cd3b41e33894f839bf9",
            "70ee218a208a47f0aec219eb806002c0",
            "610e9e17a8334307a78ea20ca7a5dea7",
            "948f059d6d61471bb12e3dba6de295ae",
            "bb0df7b4691a4fd4929db21c120dc5ed",
            "d4912c2250f14201b7d96f3b4065e0df",
            "e5220b36f5f1463b929cc65425d3a1af",
            "0e3a55188bd84a1883beed9ea65f90bf",
            "f14b9e39cc354562918685b3670fe637",
            "6eccb71baf5c43a6b8c3a1623d0e1572",
            "e7540b8537dc405b8ae5f1a58cd5ffe5",
            "69f18004bf7b46a98a5cda8a53870550",
            "bd225e1e947f4b8c9b4c239ac9b2af79",
            "57548dca7e9b4525b898a18159cd2254",
            "0f96ca76911d494f85d67d21c2fb9a68",
            "bbfbe1f9893945d19976e0bdba49ccd0",
            "2c807d8e594f42ba89c28d3f7e7b5338",
            "9ccdf75666b749e49ae54fe4baf1d95a",
            "ab4b52142eb1441ab4930cd096926fdc",
            "17af86d7a7bb4420a935f6d4a6a9c6e3",
            "eb8f10c4268248dcaba50c10cdb5172f",
            "cf18b4206bed4377aa883e8ef9969213",
            "ff60e59d740b42aa8ee0a76ce5927d2c",
            "4f80d4580f6545b58f4511ac3b3dd651",
            "ffc81d1ff091430da41b29281b78658e",
            "b7d394d56d2e4a438cf0ffe984dafa15",
            "0a74d869ef5842b7a7792c41931af320",
            "a8e7467fa12f489fb103ed32478d2981",
            "df3364882f474637bf0dcfc2eb4ba088",
            "05d70adf360146d89a55553e1725818c",
            "1c6af161fa0242c995ce011227850094",
            "4d7f524940f64ac1b0873b00492e364e",
            "9ff0c3fd97a34feaa4735a032e41a22f",
            "ee2996c09c36407a9be5e04f2231718e",
            "ec68850195aa41dcaf25701d0a4eac20",
            "a66f015fe45447b2b8d6388786bddd8f",
            "86c9a7a9d79d47a0ae2ca6f28e7c0837",
            "951b94aa516a42629abac59d7c3d97a2",
            "229d425427c14f529f4c99435c76f1bd",
            "0e9ae4c84b3d4d4bb83f7881cc34c781",
            "4bf09704a3f64ea691061255fe9c7a80",
            "019e1600a0ef468aa93dc797f5624638",
            "c93a0f5d02864555b1c313a914ed6f8d",
            "72bf9aef5bf44e6f8fc542f9a5197026",
            "a203f8d23e324ec8aea2560a92cb43f3",
            "6b34664e2efa4a5dad36d390770e0ccb",
            "9190f1d5dc504640b72ab803a9817fce",
            "eeaf3f9618664774be13decb46462ad9"
          ]
        },
        "id": "iLZ4mB9K25UM",
        "outputId": "7c21ee1f-1361-4e1a-95eb-9fcfdb6da509"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cb478d734ab74ac7b5537befb46c9802"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-large-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.23.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bb0df7b4691a4fd4929db21c120dc5ed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/pytorch_model.bin\n",
            "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bbfbe1f9893945d19976e0bdba49ccd0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-large-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.23.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a74d869ef5842b7a7792c41931af320"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "951b94aa516a42629abac59d7c3d97a2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/vocab.txt\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/tokenizer_config.json\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-large-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.23.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model_name = \"bert-large-uncased\" \n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name) \n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, do_lower_case=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cG_LLZiD4QlA",
        "outputId": "3b625bf3-2336-4725-c90a-43271bd05d89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2308: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original:  A day was twenty-four hours long but seemed longer.\n",
            "Token IDs: [101, 100, 2038, 1037, 2200, 8052, 3716, 2055, 1996, 8605, 5130, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "MASK IDs: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "101 102\n"
          ]
        }
      ],
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for i in range(len(df)):\n",
        "    tokenizer.padding_side = 'right'\n",
        "    encoded_sent = tokenizer.encode_plus(\n",
        "                        df['sentence'][i],  \n",
        "                        add_special_tokens = True, \n",
        "                        max_length = MAX_LEN,\n",
        "                        pad_to_max_length = True\n",
        "                        )\n",
        "\n",
        "    input_ids.append(encoded_sent['input_ids'])\n",
        "    attention_masks.append(encoded_sent['attention_mask'])\n",
        "\n",
        "print('original: ' , df['sentence'][100])\n",
        "print('Token IDs:', input_ids[-1])\n",
        "print('MASK IDs:', attention_masks[-1])\n",
        "print(tokenizer.cls_token_id, tokenizer.sep_token_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RquZm8Q68lqR",
        "outputId": "fb55b0f4-15be-4fe8-dd1e-81165fd6f4ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of samples:  1418\n"
          ]
        }
      ],
      "source": [
        "print(\"Total number of samples: \", len(input_ids))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "KrCbbajK-kud"
      },
      "outputs": [],
      "source": [
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    print(pred_flat, labels_flat)\n",
        "    return f1_score(labels_flat, pred_flat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "8qXEQ-me-nox"
      },
      "outputs": [],
      "source": [
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    \n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    \n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3LmlEBodDjis",
        "outputId": "2dd27d6f-9673-49d8-9b4d-6b1f89deaf5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---------------------------------FOLD NO:  0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-large-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.23.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/pytorch_model.bin\n",
            "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-large-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.23.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/vocab.txt\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/tokenizer_config.json\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-large-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.23.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(train_dataloader) 80\n",
            "total_steps 800\n",
            "warmup_steps 48\n",
            "\n",
            "======== Epoch 1 / 10 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:249: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    40  of     80.    Elapsed: 0:00:30    LR . 8.33E-06\n",
            "\n",
            "  Average training loss: 0.67\n",
            "  Training epcoh took: 0:00:58\n",
            "\n",
            "Running Validation...\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0]\n",
            "0.0\n",
            "[0 1 0 0 0 0 0 0 0 1 0 1 1 0 1 0] [1 1 1 0 1 1 0 0 0 1 0 1 1 1 0 0]\n",
            "0.5714285714285714\n",
            "[1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0] [1 1 1 0 1 0 1 0 1 0 0 0 1 0 1 1]\n",
            "0.3333333333333333\n",
            "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0] [1 1 1 1 0 0 1 1 0 1 1 0 0 0 0 0]\n",
            "0.0\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0]\n",
            "0.0\n",
            "[0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1] [1 1 0 0 1 0 0 1 0 0 0 1 0 1 1 1]\n",
            "0.36363636363636365\n",
            "[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0] [1 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0]\n",
            "0.2857142857142857\n",
            "[0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0] [0 1 1 1 0 0 0 1 0 1 1 1 1 1 0 0]\n",
            "0.3636363636363636\n",
            "[1 1 0 0 0 1 0 0 0 0 0 0 1 1] [1 1 0 0 0 1 1 0 0 1 0 0 0 0]\n",
            "0.6\n",
            "  Accuracy: 0.28\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 2 / 10 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:249: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    40  of     80.    Elapsed: 0:00:27    LR . 9.04E-06\n",
            "\n",
            "  Average training loss: 0.52\n",
            "  Training epcoh took: 0:00:55\n",
            "\n",
            "Running Validation...\n",
            "[1 0 1 0 1 0 0 0 0 1 1 1 0 0 1 0] [0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0]\n",
            "0.7272727272727273\n",
            "[1 1 1 0 0 1 1 0 0 1 0 1 1 0 1 0] [1 1 1 0 1 1 0 0 0 1 0 1 1 1 0 0]\n",
            "0.7777777777777778\n",
            "[1 0 1 0 1 0 1 0 1 0 0 1 1 0 0 0] [1 1 1 0 1 0 1 0 1 0 0 0 1 0 1 1]\n",
            "0.75\n",
            "[1 1 0 1 1 1 0 1 0 1 1 0 0 0 1 0] [1 1 1 1 0 0 1 1 0 1 1 0 0 0 0 0]\n",
            "0.7058823529411765\n",
            "[0 0 1 0 0 0 1 1 0 1 0 1 1 1 1 0] [1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0]\n",
            "0.5\n",
            "[0 1 0 1 1 0 0 1 0 0 0 1 0 1 1 1] [1 1 0 0 1 0 0 1 0 0 0 1 0 1 1 1]\n",
            "0.875\n",
            "[0 1 1 1 0 1 0 0 0 0 1 0 1 0 1 0] [1 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0]\n",
            "0.6153846153846153\n",
            "[0 1 1 1 0 0 0 1 0 1 1 0 1 1 0 0] [0 1 1 1 0 0 0 1 0 1 1 1 1 1 0 0]\n",
            "0.9411764705882353\n",
            "[1 1 0 0 0 1 0 0 0 0 0 0 1 1] [1 1 0 0 0 1 1 0 0 1 0 0 0 0]\n",
            "0.6\n",
            "  Accuracy: 0.72\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 3 / 10 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:249: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    40  of     80.    Elapsed: 0:00:28    LR . 7.98E-06\n",
            "\n",
            "  Average training loss: 0.38\n",
            "  Training epcoh took: 0:00:55\n",
            "\n",
            "Running Validation...\n",
            "[0 0 1 0 0 1 0 0 0 1 1 1 0 0 1 0] [0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0]\n",
            "0.6\n",
            "[1 1 1 1 0 1 0 0 0 1 0 1 1 0 1 0] [1 1 1 0 1 1 0 0 0 1 0 1 1 1 0 0]\n",
            "0.7777777777777778\n",
            "[1 0 0 0 1 0 1 0 1 0 0 1 1 0 0 1] [1 1 1 0 1 0 1 0 1 0 0 0 1 0 1 1]\n",
            "0.75\n",
            "[1 1 0 1 1 0 0 1 0 0 1 0 0 0 0 0] [1 1 1 1 0 0 1 1 0 1 1 0 0 0 0 0]\n",
            "0.7142857142857143\n",
            "[0 0 1 0 0 0 1 1 0 1 0 1 1 1 1 0] [1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0]\n",
            "0.5\n",
            "[0 1 0 1 0 0 0 1 0 0 0 1 0 1 1 1] [1 1 0 0 1 0 0 1 0 0 0 1 0 1 1 1]\n",
            "0.7999999999999999\n",
            "[0 1 1 1 0 1 0 0 0 0 1 0 1 0 1 0] [1 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0]\n",
            "0.6153846153846153\n",
            "[0 1 0 1 0 0 0 1 0 1 1 1 1 1 0 0] [0 1 1 1 0 0 0 1 0 1 1 1 1 1 0 0]\n",
            "0.9411764705882353\n",
            "[1 1 0 0 0 1 1 0 0 0 0 0 1 1] [1 1 0 0 0 1 1 0 0 1 0 0 0 0]\n",
            "0.7272727272727272\n",
            "  Accuracy: 0.71\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 4 / 10 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:249: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    40  of     80.    Elapsed: 0:00:27    LR . 6.91E-06\n",
            "\n",
            "  Average training loss: 0.24\n",
            "  Training epcoh took: 0:00:55\n",
            "\n",
            "Running Validation...\n",
            "[0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0] [0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0]\n",
            "0.3333333333333333\n",
            "[1 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0] [1 1 1 0 1 1 0 0 0 1 0 1 1 1 0 0]\n",
            "0.7142857142857143\n",
            "[1 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0] [1 1 1 0 1 0 1 0 1 0 0 0 1 0 1 1]\n",
            "0.5714285714285714\n",
            "[1 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0] [1 1 1 1 0 0 1 1 0 1 1 0 0 0 0 0]\n",
            "0.5\n",
            "[0 0 1 0 0 0 0 0 0 1 0 1 1 0 1 0] [1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0]\n",
            "0.6666666666666665\n",
            "[0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0] [1 1 0 0 1 0 0 1 0 0 0 1 0 1 1 1]\n",
            "0.5454545454545454\n",
            "[0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0] [1 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0]\n",
            "0.5\n",
            "[0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0] [0 1 1 1 0 0 0 1 0 1 1 1 1 1 0 0]\n",
            "0.6153846153846153\n",
            "[1 1 0 0 0 1 0 0 0 0 0 0 1 1] [1 1 0 0 0 1 1 0 0 1 0 0 0 0]\n",
            "0.6\n",
            "  Accuracy: 0.56\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 5 / 10 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:249: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    40  of     80.    Elapsed: 0:00:27    LR . 5.85E-06\n",
            "\n",
            "  Average training loss: 0.15\n",
            "  Training epcoh took: 0:00:54\n",
            "\n",
            "Running Validation...\n",
            "[0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0] [0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0]\n",
            "0.28571428571428575\n",
            "[1 1 1 0 0 1 0 0 0 1 0 1 1 0 0 0] [1 1 1 0 1 1 0 0 0 1 0 1 1 1 0 0]\n",
            "0.8750000000000001\n",
            "[1 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0] [1 1 1 0 1 0 1 0 1 0 0 0 1 0 1 1]\n",
            "0.5714285714285714\n",
            "[1 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0] [1 1 1 1 0 0 1 1 0 1 1 0 0 0 0 0]\n",
            "0.5\n",
            "[0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0] [1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0]\n",
            "0.75\n",
            "[0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0] [1 1 0 0 1 0 0 1 0 0 0 1 0 1 1 1]\n",
            "0.5\n",
            "[0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0] [1 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0]\n",
            "0.6666666666666666\n",
            "[0 0 0 1 0 0 0 1 0 0 0 1 1 1 0 0] [0 1 1 1 0 0 0 1 0 1 1 1 1 1 0 0]\n",
            "0.7142857142857143\n",
            "[1 1 0 0 0 1 0 0 0 0 0 0 1 1] [1 1 0 0 0 1 1 0 0 1 0 0 0 0]\n",
            "0.6\n",
            "  Accuracy: 0.61\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 6 / 10 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:249: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    40  of     80.    Elapsed: 0:00:27    LR . 4.79E-06\n",
            "\n",
            "  Average training loss: 0.11\n",
            "  Training epcoh took: 0:00:54\n",
            "\n",
            "Running Validation...\n",
            "[0 0 1 0 1 1 0 0 0 1 0 1 0 0 1 0] [0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0]\n",
            "0.6\n",
            "[1 1 1 0 1 1 1 0 0 1 0 1 1 0 1 0] [1 1 1 0 1 1 0 0 0 1 0 1 1 1 0 0]\n",
            "0.8421052631578948\n",
            "[1 1 0 0 1 0 1 0 1 0 0 1 1 0 0 1] [1 1 1 0 1 0 1 0 1 0 0 0 1 0 1 1]\n",
            "0.823529411764706\n",
            "[1 1 0 1 1 0 0 0 0 1 1 0 0 0 0 0] [1 1 1 1 0 0 1 1 0 1 1 0 0 0 0 0]\n",
            "0.7142857142857143\n",
            "[1 0 1 0 0 0 1 0 0 1 0 1 1 1 1 0] [1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0]\n",
            "0.6666666666666666\n",
            "[0 1 0 1 1 0 1 1 0 0 0 1 0 1 1 1] [1 1 0 0 1 0 0 1 0 0 0 1 0 1 1 1]\n",
            "0.823529411764706\n",
            "[1 1 1 1 0 1 0 0 0 0 1 0 1 0 0 0] [1 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0]\n",
            "0.7692307692307692\n",
            "[0 1 0 1 0 0 0 1 0 0 1 1 1 1 0 0] [0 1 1 1 0 0 0 1 0 1 1 1 1 1 0 0]\n",
            "0.8750000000000001\n",
            "[1 1 0 0 0 1 1 0 0 0 0 0 1 1] [1 1 0 0 0 1 1 0 0 1 0 0 0 0]\n",
            "0.7272727272727272\n",
            "  Accuracy: 0.76\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 7 / 10 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:249: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    40  of     80.    Elapsed: 0:00:27    LR . 3.72E-06\n",
            "\n",
            "  Average training loss: 0.07\n",
            "  Training epcoh took: 0:00:54\n",
            "\n",
            "Running Validation...\n",
            "[0 0 1 0 0 1 0 0 0 1 0 1 0 0 1 0] [0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0]\n",
            "0.4444444444444445\n",
            "[1 1 1 0 1 1 1 0 0 1 0 1 1 0 1 0] [1 1 1 0 1 1 0 0 0 1 0 1 1 1 0 0]\n",
            "0.8421052631578948\n",
            "[1 1 0 0 1 0 1 0 1 0 0 1 1 0 0 1] [1 1 1 0 1 0 1 0 1 0 0 0 1 0 1 1]\n",
            "0.823529411764706\n",
            "[1 1 0 1 1 0 0 0 0 1 1 0 0 0 0 0] [1 1 1 1 0 0 1 1 0 1 1 0 0 0 0 0]\n",
            "0.7142857142857143\n",
            "[0 0 1 0 0 0 1 0 0 1 0 1 1 1 1 0] [1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0]\n",
            "0.5454545454545454\n",
            "[0 1 0 1 0 0 1 1 0 0 0 1 0 1 1 1] [1 1 0 0 1 0 0 1 0 0 0 1 0 1 1 1]\n",
            "0.75\n",
            "[0 1 1 0 0 1 0 0 0 0 1 0 1 0 0 0] [1 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0]\n",
            "0.7272727272727272\n",
            "[0 1 0 1 0 0 0 1 0 0 1 1 1 1 0 0] [0 1 1 1 0 0 0 1 0 1 1 1 1 1 0 0]\n",
            "0.8750000000000001\n",
            "[1 1 0 0 0 1 1 0 0 0 0 0 1 1] [1 1 0 0 0 1 1 0 0 1 0 0 0 0]\n",
            "0.7272727272727272\n",
            "  Accuracy: 0.72\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 8 / 10 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:249: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    40  of     80.    Elapsed: 0:00:27    LR . 2.66E-06\n",
            "\n",
            "  Average training loss: 0.06\n",
            "  Training epcoh took: 0:00:54\n",
            "\n",
            "Running Validation...\n",
            "[0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0] [0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0]\n",
            "0.5\n",
            "[1 1 1 0 0 1 0 0 0 1 0 1 1 0 1 0] [1 1 1 0 1 1 0 0 0 1 0 1 1 1 0 0]\n",
            "0.823529411764706\n",
            "[1 1 0 0 1 0 1 0 1 0 0 1 1 0 0 1] [1 1 1 0 1 0 1 0 1 0 0 0 1 0 1 1]\n",
            "0.823529411764706\n",
            "[1 1 0 1 1 0 0 0 0 1 1 0 0 0 0 0] [1 1 1 1 0 0 1 1 0 1 1 0 0 0 0 0]\n",
            "0.7142857142857143\n",
            "[0 0 1 0 0 0 0 0 0 1 0 1 1 0 1 0] [1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0]\n",
            "0.6666666666666665\n",
            "[0 1 0 1 0 0 1 1 0 0 0 1 0 0 1 0] [1 1 0 0 1 0 0 1 0 0 0 1 0 1 1 1]\n",
            "0.5714285714285715\n",
            "[0 1 1 0 0 1 0 0 0 0 1 0 1 0 0 0] [1 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0]\n",
            "0.7272727272727272\n",
            "[0 1 0 1 0 0 0 1 0 0 0 1 1 1 0 0] [0 1 1 1 0 0 0 1 0 1 1 1 1 1 0 0]\n",
            "0.8\n",
            "[1 1 0 0 0 1 1 0 0 0 0 0 1 1] [1 1 0 0 0 1 1 0 0 1 0 0 0 0]\n",
            "0.7272727272727272\n",
            "  Accuracy: 0.71\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 9 / 10 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:249: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    40  of     80.    Elapsed: 0:00:27    LR . 1.60E-06\n",
            "\n",
            "  Average training loss: 0.04\n",
            "  Training epcoh took: 0:00:54\n",
            "\n",
            "Running Validation...\n",
            "[0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0] [0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0]\n",
            "0.5\n",
            "[1 1 1 0 0 1 0 0 0 1 0 1 1 0 1 0] [1 1 1 0 1 1 0 0 0 1 0 1 1 1 0 0]\n",
            "0.823529411764706\n",
            "[1 1 0 0 1 0 1 0 1 0 0 1 1 0 0 1] [1 1 1 0 1 0 1 0 1 0 0 0 1 0 1 1]\n",
            "0.823529411764706\n",
            "[1 1 0 1 1 0 0 0 0 1 1 0 0 0 0 0] [1 1 1 1 0 0 1 1 0 1 1 0 0 0 0 0]\n",
            "0.7142857142857143\n",
            "[0 0 1 0 0 0 1 0 0 1 0 1 1 0 1 0] [1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0]\n",
            "0.6\n",
            "[0 1 0 1 0 0 1 1 0 0 0 1 0 1 1 1] [1 1 0 0 1 0 0 1 0 0 0 1 0 1 1 1]\n",
            "0.75\n",
            "[0 1 1 0 0 1 0 0 0 0 1 0 1 0 0 0] [1 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0]\n",
            "0.7272727272727272\n",
            "[0 1 0 1 0 0 0 1 0 0 1 1 1 1 0 0] [0 1 1 1 0 0 0 1 0 1 1 1 1 1 0 0]\n",
            "0.8750000000000001\n",
            "[1 1 0 0 0 1 1 0 0 0 0 0 1 1] [1 1 0 0 0 1 1 0 0 1 0 0 0 0]\n",
            "0.7272727272727272\n",
            "  Accuracy: 0.73\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 10 / 10 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:249: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    40  of     80.    Elapsed: 0:00:27    LR . 5.32E-07\n",
            "\n",
            "  Average training loss: 0.03\n",
            "  Training epcoh took: 0:00:54\n",
            "\n",
            "Running Validation...\n",
            "[0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0] [0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0]\n",
            "0.5\n",
            "[1 1 1 0 1 1 0 0 0 1 0 1 1 0 1 0] [1 1 1 0 1 1 0 0 0 1 0 1 1 1 0 0]\n",
            "0.8888888888888888\n",
            "[1 1 0 0 1 0 1 0 1 0 0 1 1 0 0 1] [1 1 1 0 1 0 1 0 1 0 0 0 1 0 1 1]\n",
            "0.823529411764706\n",
            "[1 1 0 1 1 0 0 0 0 1 1 0 0 0 0 0] [1 1 1 1 0 0 1 1 0 1 1 0 0 0 0 0]\n",
            "0.7142857142857143\n",
            "[0 0 1 0 0 0 1 0 0 1 0 1 1 0 1 0] [1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0]\n",
            "0.6\n",
            "[0 1 0 1 0 0 1 1 0 0 0 1 0 1 1 1] [1 1 0 0 1 0 0 1 0 0 0 1 0 1 1 1]\n",
            "0.75\n",
            "[0 1 1 0 0 1 0 0 0 0 1 0 1 0 0 0] [1 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0]\n",
            "0.7272727272727272\n",
            "[0 1 0 1 0 0 0 1 0 0 1 1 1 1 0 0] [0 1 1 1 0 0 0 1 0 1 1 1 1 1 0 0]\n",
            "0.8750000000000001\n",
            "[1 1 0 0 0 1 1 0 0 0 0 0 1 1] [1 1 0 0 0 1 1 0 0 1 0 0 0 0]\n",
            "0.7272727272727272\n",
            "  Accuracy: 0.73\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "Training complete!\n",
            "Predicting labels for 142 dev sentences...\n",
            "    DONE.\n",
            "---------------------------------Confusion Matrix------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    0   1\n",
              "0  67  13\n",
              "1  16  46"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0977ec79-fd05-4985-9bae-cf4b048ba016\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>67</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>16</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0977ec79-fd05-4985-9bae-cf4b048ba016')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0977ec79-fd05-4985-9bae-cf4b048ba016 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0977ec79-fd05-4985-9bae-cf4b048ba016');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------Evaluation Metrics------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "              precision    recall  f1-score\n",
              "0              0.807229  0.837500  0.822086\n",
              "1              0.779661  0.741935  0.760331\n",
              "accuracy       0.795775  0.795775  0.795775\n",
              "macro avg      0.793445  0.789718  0.791208\n",
              "weighted avg   0.795192  0.795775  0.795122"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b63d374e-af63-4833-bb3a-c01bd6797d0b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1-score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.807229</td>\n",
              "      <td>0.837500</td>\n",
              "      <td>0.822086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.779661</td>\n",
              "      <td>0.741935</td>\n",
              "      <td>0.760331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>accuracy</th>\n",
              "      <td>0.795775</td>\n",
              "      <td>0.795775</td>\n",
              "      <td>0.795775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>macro avg</th>\n",
              "      <td>0.793445</td>\n",
              "      <td>0.789718</td>\n",
              "      <td>0.791208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weighted avg</th>\n",
              "      <td>0.795192</td>\n",
              "      <td>0.795775</td>\n",
              "      <td>0.795122</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b63d374e-af63-4833-bb3a-c01bd6797d0b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b63d374e-af63-4833-bb3a-c01bd6797d0b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b63d374e-af63-4833-bb3a-c01bd6797d0b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                  F1-score  F0.5-score  F2-score\n",
              "Micro-Average     0.795775    0.795775  0.795775\n",
              "Macro-Average     0.791208    0.792459  0.790226\n",
              "Weighted-Average  0.795122    0.795077  0.795428"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-79852927-d602-40ae-b056-be73494ccc69\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>F1-score</th>\n",
              "      <th>F0.5-score</th>\n",
              "      <th>F2-score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Micro-Average</th>\n",
              "      <td>0.795775</td>\n",
              "      <td>0.795775</td>\n",
              "      <td>0.795775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Macro-Average</th>\n",
              "      <td>0.791208</td>\n",
              "      <td>0.792459</td>\n",
              "      <td>0.790226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Weighted-Average</th>\n",
              "      <td>0.795122</td>\n",
              "      <td>0.795077</td>\n",
              "      <td>0.795428</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-79852927-d602-40ae-b056-be73494ccc69')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-79852927-d602-40ae-b056-be73494ccc69 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-79852927-d602-40ae-b056-be73494ccc69');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------Normalized Matrix------------------------------------\n",
            "\n",
            "---------------------------------FOLD NO:  1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-large-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.23.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/pytorch_model.bin\n",
            "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-large-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.23.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/vocab.txt\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/tokenizer_config.json\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-large-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.23.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(train_dataloader) 80\n",
            "total_steps 800\n",
            "warmup_steps 48\n",
            "\n",
            "======== Epoch 1 / 10 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:249: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    40  of     80.    Elapsed: 0:00:27    LR . 8.33E-06\n",
            "\n",
            "  Average training loss: 0.70\n",
            "  Training epcoh took: 0:00:55\n",
            "\n",
            "Running Validation...\n",
            "[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0] [0 0 0 1 1 1 0 1 1 1 1 1 1 1 0 0]\n",
            "0.18181818181818182\n",
            "[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0] [1 1 1 0 0 0 0 0 1 0 0 0 1 1 0 0]\n",
            "0.2857142857142857\n",
            "[0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0] [1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 0]\n",
            "0.4\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [0 1 0 0 0 1 1 1 0 1 1 1 0 1 1 1]\n",
            "0.0\n",
            "[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0] [0 0 1 1 1 0 0 0 0 1 1 0 0 0 0 0]\n",
            "0.33333333333333337\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [0 0 0 1 0 0 0 0 0 1 1 1 0 0 1 0]\n",
            "0.0\n",
            "[0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0] [0 0 0 0 0 0 1 1 1 0 0 1 1 0 1 0]\n",
            "0.6666666666666666\n",
            "[0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0] [1 1 0 1 0 0 1 1 1 0 1 0 0 0 1 1]\n",
            "0.1818181818181818\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0] [0 0 0 0 0 0 1 1 0 0 0 0 1 1]\n",
            "0.0\n",
            "  Accuracy: 0.23\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 2 / 10 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:249: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    40  of     80.    Elapsed: 0:00:27    LR . 9.04E-06\n",
            "\n",
            "  Average training loss: 0.61\n",
            "  Training epcoh took: 0:00:54\n",
            "\n",
            "Running Validation...\n",
            "[0 0 0 0 1 0 0 0 1 1 1 0 0 1 0 0] [0 0 0 1 1 1 0 1 1 1 1 1 1 1 0 0]\n",
            "0.6666666666666666\n",
            "[0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0] [1 1 1 0 0 0 0 0 1 0 0 0 1 1 0 0]\n",
            "0.25\n",
            "[1 0 0 0 0 0 0 0 1 1 0 1 1 1 1 0] [1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 0]\n",
            "0.6666666666666666\n",
            "[0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1] [0 1 0 0 0 1 1 1 0 1 1 1 0 1 1 1]\n",
            "0.4285714285714285\n",
            "[0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0] [0 0 1 1 1 0 0 0 0 1 1 0 0 0 0 0]\n",
            "0.5714285714285715\n",
            "[0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0] [0 0 0 1 0 0 0 0 0 1 1 1 0 0 1 0]\n",
            "0.7499999999999999\n",
            "[0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0] [0 0 0 0 0 0 1 1 1 0 0 1 1 0 1 0]\n",
            "0.6\n",
            "[0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0] [1 1 0 1 0 0 1 1 1 0 1 0 0 0 1 1]\n",
            "0.3333333333333333\n",
            "[0 0 0 0 0 0 1 0 0 0 0 0 1 1] [0 0 0 0 0 0 1 1 0 0 0 0 1 1]\n",
            "0.8571428571428571\n",
            "  Accuracy: 0.57\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 3 / 10 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:249: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    40  of     80.    Elapsed: 0:00:27    LR . 7.98E-06\n",
            "\n",
            "  Average training loss: 0.48\n",
            "  Training epcoh took: 0:00:54\n",
            "\n",
            "Running Validation...\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1 1 1 0 0] [0 0 0 1 1 1 0 1 1 1 1 1 1 1 0 0]\n",
            "0.888888888888889\n",
            "[0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0] [1 1 1 0 0 0 0 0 1 0 0 0 1 1 0 0]\n",
            "0.6\n",
            "[1 0 1 0 0 1 0 0 0 1 0 1 1 1 1 0] [1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 0]\n",
            "0.875\n",
            "[1 0 0 0 1 1 0 0 0 0 1 1 0 0 1 1] [0 1 0 0 0 1 1 1 0 1 1 1 0 1 1 1]\n",
            "0.588235294117647\n",
            "[0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0] [0 0 1 1 1 0 0 0 0 1 1 0 0 0 0 0]\n",
            "0.888888888888889\n",
            "[0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0] [0 0 0 1 0 0 0 0 0 1 1 1 0 0 1 0]\n",
            "0.6666666666666665\n",
            "[0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0] [0 0 0 0 0 0 1 1 1 0 0 1 1 0 1 0]\n",
            "0.6\n",
            "[1 1 1 1 0 0 1 1 0 0 0 1 0 0 0 0] [1 1 0 1 0 0 1 1 1 0 1 0 0 0 1 1]\n",
            "0.6250000000000001\n",
            "[0 0 0 0 0 0 1 1 1 0 0 0 1 1] [0 0 0 0 0 0 1 1 0 0 0 0 1 1]\n",
            "0.888888888888889\n",
            "  Accuracy: 0.74\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 4 / 10 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:249: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    40  of     80.    Elapsed: 0:00:27    LR . 6.91E-06\n",
            "\n",
            "  Average training loss: 0.34\n",
            "  Training epcoh took: 0:00:54\n",
            "\n",
            "Running Validation...\n",
            "[0 0 0 0 1 1 0 0 1 1 1 0 0 1 0 0] [0 0 0 1 1 1 0 1 1 1 1 1 1 1 0 0]\n",
            "0.7499999999999999\n",
            "[0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0] [1 1 1 0 0 0 0 0 1 0 0 0 1 1 0 0]\n",
            "0.4444444444444444\n",
            "[1 0 1 0 0 1 0 0 0 1 0 1 0 1 1 0] [1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 0]\n",
            "0.9333333333333333\n",
            "[1 0 0 0 0 1 0 0 0 0 1 1 0 0 1 1] [0 1 0 0 0 1 1 1 0 1 1 1 0 1 1 1]\n",
            "0.625\n",
            "[0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0] [0 0 1 1 1 0 0 0 0 1 1 0 0 0 0 0]\n",
            "0.7499999999999999\n",
            "[0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0] [0 0 0 1 0 0 0 0 0 1 1 1 0 0 1 0]\n",
            "0.7499999999999999\n",
            "[0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0] [0 0 0 0 0 0 1 1 1 0 0 1 1 0 1 0]\n",
            "0.6\n",
            "[1 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0] [1 1 0 1 0 0 1 1 1 0 1 0 0 0 1 1]\n",
            "0.42857142857142855\n",
            "[0 0 0 0 0 0 1 1 1 0 0 0 1 1] [0 0 0 0 0 0 1 1 0 0 0 0 1 1]\n",
            "0.888888888888889\n",
            "  Accuracy: 0.69\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 5 / 10 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:249: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    40  of     80.    Elapsed: 0:00:27    LR . 5.85E-06\n",
            "\n",
            "  Average training loss: 0.24\n",
            "  Training epcoh took: 0:00:54\n",
            "\n",
            "Running Validation...\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1 1 1 0 0] [0 0 0 1 1 1 0 1 1 1 1 1 1 1 0 0]\n",
            "0.888888888888889\n",
            "[0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0] [1 1 1 0 0 0 0 0 1 0 0 0 1 1 0 0]\n",
            "0.6666666666666666\n",
            "[1 0 1 0 0 0 0 0 0 1 0 1 0 1 1 0] [1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 0]\n",
            "0.8571428571428571\n",
            "[1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1] [0 1 0 0 0 1 1 1 0 1 1 1 0 1 1 1]\n",
            "0.5333333333333333\n",
            "[0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0] [0 0 1 1 1 0 0 0 0 1 1 0 0 0 0 0]\n",
            "0.7499999999999999\n",
            "[0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0] [0 0 0 1 0 0 0 0 0 1 1 1 0 0 1 0]\n",
            "0.7499999999999999\n",
            "[0 1 0 0 0 0 1 0 1 0 0 1 1 0 0 0] [0 0 0 0 0 0 1 1 1 0 0 1 1 0 1 0]\n",
            "0.7272727272727272\n",
            "[1 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0] [1 1 0 1 0 0 1 1 1 0 1 0 0 0 1 1]\n",
            "0.6250000000000001\n",
            "[0 0 0 0 0 0 1 1 1 0 0 0 1 1] [0 0 0 0 0 0 1 1 0 0 0 0 1 1]\n",
            "0.888888888888889\n",
            "  Accuracy: 0.74\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 6 / 10 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:249: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    40  of     80.    Elapsed: 0:00:27    LR . 4.79E-06\n",
            "\n",
            "  Average training loss: 0.16\n",
            "  Training epcoh took: 0:00:54\n",
            "\n",
            "Running Validation...\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1 1 1 0 0] [0 0 0 1 1 1 0 1 1 1 1 1 1 1 0 0]\n",
            "0.888888888888889\n",
            "[0 1 0 0 0 0 0 1 1 0 0 0 1 1 0 0] [1 1 1 0 0 0 0 0 1 0 0 0 1 1 0 0]\n",
            "0.7272727272727272\n",
            "[1 0 1 0 0 1 0 0 1 1 0 1 1 1 1 0] [1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 0]\n",
            "0.823529411764706\n",
            "[1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1] [0 1 0 0 0 1 1 1 0 1 1 1 0 1 1 1]\n",
            "0.5333333333333333\n",
            "[0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0] [0 0 1 1 1 0 0 0 0 1 1 0 0 0 0 0]\n",
            "0.888888888888889\n",
            "[0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0] [0 0 0 1 0 0 0 0 0 1 1 1 0 0 1 0]\n",
            "0.7499999999999999\n",
            "[0 1 0 0 0 1 1 0 1 1 0 1 1 0 1 0] [0 0 0 0 0 0 1 1 1 0 0 1 1 0 1 0]\n",
            "0.7142857142857143\n",
            "[1 1 1 1 1 0 1 1 0 1 1 1 0 0 0 0] [1 1 0 1 0 0 1 1 1 0 1 0 0 0 1 1]\n",
            "0.631578947368421\n",
            "[0 0 0 0 0 0 1 1 1 0 0 0 1 1] [0 0 0 0 0 0 1 1 0 0 0 0 1 1]\n",
            "0.888888888888889\n",
            "  Accuracy: 0.76\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 7 / 10 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:249: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    40  of     80.    Elapsed: 0:00:27    LR . 3.72E-06\n",
            "\n",
            "  Average training loss: 0.12\n",
            "  Training epcoh took: 0:00:54\n",
            "\n",
            "Running Validation...\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1 1 1 0 0] [0 0 0 1 1 1 0 1 1 1 1 1 1 1 0 0]\n",
            "0.888888888888889\n",
            "[0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0] [1 1 1 0 0 0 0 0 1 0 0 0 1 1 0 0]\n",
            "0.6666666666666666\n",
            "[1 0 1 0 0 1 0 0 1 1 0 1 1 1 1 0] [1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 0]\n",
            "0.823529411764706\n",
            "[1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1] [0 1 0 0 0 1 1 1 0 1 1 1 0 1 1 1]\n",
            "0.5333333333333333\n",
            "[0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0] [0 0 1 1 1 0 0 0 0 1 1 0 0 0 0 0]\n",
            "0.7499999999999999\n",
            "[0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0] [0 0 0 1 0 0 0 0 0 1 1 1 0 0 1 0]\n",
            "0.7499999999999999\n",
            "[0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 0] [0 0 0 0 0 0 1 1 1 0 0 1 1 0 1 0]\n",
            "0.7692307692307692\n",
            "[1 1 1 1 0 0 1 1 0 1 1 1 0 0 0 0] [1 1 0 1 0 0 1 1 1 0 1 0 0 0 1 1]\n",
            "0.6666666666666666\n",
            "[0 0 0 0 0 0 1 1 1 0 0 0 1 1] [0 0 0 0 0 0 1 1 0 0 0 0 1 1]\n",
            "0.888888888888889\n",
            "  Accuracy: 0.75\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 8 / 10 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:249: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    40  of     80.    Elapsed: 0:00:27    LR . 2.66E-06\n",
            "\n",
            "  Average training loss: 0.09\n",
            "  Training epcoh took: 0:00:54\n",
            "\n",
            "Running Validation...\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1 1 1 0 0] [0 0 0 1 1 1 0 1 1 1 1 1 1 1 0 0]\n",
            "0.888888888888889\n",
            "[0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0] [1 1 1 0 0 0 0 0 1 0 0 0 1 1 0 0]\n",
            "0.5\n",
            "[1 0 1 0 0 0 0 0 0 1 0 1 1 1 1 0] [1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 0]\n",
            "0.7999999999999999\n",
            "[1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1] [0 1 0 0 0 1 1 1 0 1 1 1 0 1 1 1]\n",
            "0.5333333333333333\n",
            "[0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0] [0 0 1 1 1 0 0 0 0 1 1 0 0 0 0 0]\n",
            "0.7499999999999999\n",
            "[0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0] [0 0 0 1 0 0 0 0 0 1 1 1 0 0 1 0]\n",
            "0.7499999999999999\n",
            "[0 1 0 0 0 0 1 0 1 1 0 1 1 0 0 0] [0 0 0 0 0 0 1 1 1 0 0 1 1 0 1 0]\n",
            "0.6666666666666666\n",
            "[1 1 1 1 0 0 1 1 0 1 1 1 0 0 0 0] [1 1 0 1 0 0 1 1 1 0 1 0 0 0 1 1]\n",
            "0.6666666666666666\n",
            "[0 0 0 0 0 0 1 1 1 0 0 0 1 1] [0 0 0 0 0 0 1 1 0 0 0 0 1 1]\n",
            "0.888888888888889\n",
            "  Accuracy: 0.72\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 9 / 10 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:249: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    40  of     80.    Elapsed: 0:00:27    LR . 1.60E-06\n",
            "\n",
            "  Average training loss: 0.07\n",
            "  Training epcoh took: 0:00:54\n",
            "\n",
            "Running Validation...\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1 1 1 0 0] [0 0 0 1 1 1 0 1 1 1 1 1 1 1 0 0]\n",
            "0.888888888888889\n",
            "[0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 0] [1 1 1 0 0 0 0 0 1 0 0 0 1 1 0 0]\n",
            "0.8\n",
            "[1 0 1 0 0 0 0 0 1 1 0 1 1 1 1 0] [1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 0]\n",
            "0.75\n",
            "[1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1] [0 1 0 0 0 1 1 1 0 1 1 1 0 1 1 1]\n",
            "0.5333333333333333\n",
            "[0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0] [0 0 1 1 1 0 0 0 0 1 1 0 0 0 0 0]\n",
            "0.888888888888889\n",
            "[0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0] [0 0 0 1 0 0 0 0 0 1 1 1 0 0 1 0]\n",
            "0.7499999999999999\n",
            "[0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 0] [0 0 0 0 0 0 1 1 1 0 0 1 1 0 1 0]\n",
            "0.7692307692307692\n",
            "[1 1 1 1 1 0 1 1 0 1 1 1 0 0 0 0] [1 1 0 1 0 0 1 1 1 0 1 0 0 0 1 1]\n",
            "0.631578947368421\n",
            "[0 0 0 0 0 0 1 1 1 0 0 0 1 1] [0 0 0 0 0 0 1 1 0 0 0 0 1 1]\n",
            "0.888888888888889\n",
            "  Accuracy: 0.77\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 10 / 10 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:249: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    40  of     80.    Elapsed: 0:00:27    LR . 5.32E-07\n",
            "\n",
            "  Average training loss: 0.06\n",
            "  Training epcoh took: 0:00:54\n",
            "\n",
            "Running Validation...\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1 1 1 0 0] [0 0 0 1 1 1 0 1 1 1 1 1 1 1 0 0]\n",
            "0.888888888888889\n",
            "[0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 0] [1 1 1 0 0 0 0 0 1 0 0 0 1 1 0 0]\n",
            "0.8\n",
            "[1 0 1 0 0 0 0 0 1 1 0 1 1 1 1 0] [1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 0]\n",
            "0.75\n",
            "[1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1] [0 1 0 0 0 1 1 1 0 1 1 1 0 1 1 1]\n",
            "0.5333333333333333\n",
            "[0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0] [0 0 1 1 1 0 0 0 0 1 1 0 0 0 0 0]\n",
            "0.7499999999999999\n",
            "[0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0] [0 0 0 1 0 0 0 0 0 1 1 1 0 0 1 0]\n",
            "0.7499999999999999\n",
            "[0 1 0 0 0 0 1 0 1 1 0 1 1 0 1 0] [0 0 0 0 0 0 1 1 1 0 0 1 1 0 1 0]\n",
            "0.7692307692307692\n",
            "[1 1 1 1 1 0 1 1 0 1 1 1 0 0 0 0] [1 1 0 1 0 0 1 1 1 0 1 0 0 0 1 1]\n",
            "0.631578947368421\n",
            "[0 0 0 0 0 0 1 1 1 0 0 0 1 1] [0 0 0 0 0 0 1 1 0 0 0 0 1 1]\n",
            "0.888888888888889\n",
            "  Accuracy: 0.75\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "Training complete!\n",
            "Predicting labels for 142 dev sentences...\n",
            "    DONE.\n",
            "---------------------------------Confusion Matrix------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    0   1\n",
              "0  69  10\n",
              "1  20  43"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a2503c80-a13a-4038-a08a-4294cd75aa74\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>69</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a2503c80-a13a-4038-a08a-4294cd75aa74')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a2503c80-a13a-4038-a08a-4294cd75aa74 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a2503c80-a13a-4038-a08a-4294cd75aa74');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------Evaluation Metrics------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "              precision    recall  f1-score\n",
              "0              0.775281  0.873418  0.821429\n",
              "1              0.811321  0.682540  0.741379\n",
              "accuracy       0.788732  0.788732  0.788732\n",
              "macro avg      0.793301  0.777979  0.781404\n",
              "weighted avg   0.791270  0.788732  0.785914"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-92c6cbbf-09e7-401b-980a-9912e6f0ae1e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1-score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.775281</td>\n",
              "      <td>0.873418</td>\n",
              "      <td>0.821429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.811321</td>\n",
              "      <td>0.682540</td>\n",
              "      <td>0.741379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>accuracy</th>\n",
              "      <td>0.788732</td>\n",
              "      <td>0.788732</td>\n",
              "      <td>0.788732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>macro avg</th>\n",
              "      <td>0.793301</td>\n",
              "      <td>0.777979</td>\n",
              "      <td>0.781404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weighted avg</th>\n",
              "      <td>0.791270</td>\n",
              "      <td>0.788732</td>\n",
              "      <td>0.785914</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-92c6cbbf-09e7-401b-980a-9912e6f0ae1e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-92c6cbbf-09e7-401b-980a-9912e6f0ae1e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-92c6cbbf-09e7-401b-980a-9912e6f0ae1e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                  F1-score  F0.5-score  F2-score\n",
              "Micro-Average     0.788732    0.788732  0.788732\n",
              "Macro-Average     0.781404    0.787461  0.778385\n",
              "Weighted-Average  0.785914    0.788097  0.786663"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-235d950f-d033-48ef-a128-2585e2a17735\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>F1-score</th>\n",
              "      <th>F0.5-score</th>\n",
              "      <th>F2-score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Micro-Average</th>\n",
              "      <td>0.788732</td>\n",
              "      <td>0.788732</td>\n",
              "      <td>0.788732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Macro-Average</th>\n",
              "      <td>0.781404</td>\n",
              "      <td>0.787461</td>\n",
              "      <td>0.778385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Weighted-Average</th>\n",
              "      <td>0.785914</td>\n",
              "      <td>0.788097</td>\n",
              "      <td>0.786663</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-235d950f-d033-48ef-a128-2585e2a17735')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-235d950f-d033-48ef-a128-2585e2a17735 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-235d950f-d033-48ef-a128-2585e2a17735');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------Normalized Matrix------------------------------------\n",
            "\n",
            "---------------------------------FOLD NO:  0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-large-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.23.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/pytorch_model.bin\n",
            "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-large-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.23.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/vocab.txt\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/tokenizer_config.json\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-large-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.23.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(train_dataloader) 80\n",
            "total_steps 800\n",
            "warmup_steps 48\n",
            "\n",
            "======== Epoch 1 / 10 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:249: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    40  of     80.    Elapsed: 0:00:27    LR . 8.33E-06\n",
            "\n",
            "  Average training loss: 0.69\n",
            "  Training epcoh took: 0:00:55\n",
            "\n",
            "Running Validation...\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [0 0 0 1 1 1 0 1 1 0 1 0 1 1 0 1]\n",
            "0.0\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0] [0 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0]\n",
            "0.4\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [0 1 0 0 0 1 0 1 1 0 0 0 1 1 1 0]\n",
            "0.0\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [0 0 1 1 1 0 0 1 0 1 1 0 1 1 0 1]\n",
            "0.0\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [0 1 1 0 0 1 0 0 0 0 1 0 1 1 1 1]\n",
            "0.0\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [1 0 1 0 1 1 1 1 0 1 0 0 0 0 0 0]\n",
            "0.0\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [0 0 0 0 1 0 1 0 1 0 1 1 1 0 1 0]\n",
            "0.0\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [0 0 0 1 1 1 0 1 0 0 0 0 1 0 0 1]\n",
            "0.0\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0] [0 0 0 1 0 1 0 1 1 0 0 0 0 1]\n",
            "0.0\n",
            "  Accuracy: 0.04\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 2 / 10 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:249: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    40  of     80.    Elapsed: 0:00:27    LR . 9.04E-06\n",
            "\n",
            "  Average training loss: 0.61\n",
            "  Training epcoh took: 0:00:54\n",
            "\n",
            "Running Validation...\n",
            "[0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 1] [0 0 0 1 1 1 0 1 1 0 1 0 1 1 0 1]\n",
            "0.42857142857142855\n",
            "[0 0 1 0 1 0 0 1 0 0 0 1 1 1 1 0] [0 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0]\n",
            "0.5454545454545454\n",
            "[1 1 0 0 0 1 0 1 1 1 0 0 1 1 1 0] [0 1 0 0 0 1 0 1 1 0 0 0 1 1 1 0]\n",
            "0.8750000000000001\n",
            "[0 0 1 1 1 0 0 1 0 0 1 0 1 1 1 1] [0 0 1 1 1 0 0 1 0 1 1 0 1 1 0 1]\n",
            "0.8888888888888888\n",
            "[1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0] [0 1 1 0 0 1 0 0 0 0 1 0 1 1 1 1]\n",
            "0.5\n",
            "[1 0 1 0 1 1 0 1 0 1 0 0 0 0 0 0] [1 0 1 0 1 1 1 1 0 1 0 0 0 0 0 0]\n",
            "0.923076923076923\n",
            "[0 1 1 0 0 0 1 0 0 0 1 0 1 0 1 0] [0 0 0 0 1 0 1 0 1 0 1 1 1 0 1 0]\n",
            "0.6153846153846153\n",
            "[0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0] [0 0 0 1 1 1 0 1 0 0 0 0 1 0 0 1]\n",
            "0.4444444444444444\n",
            "[0 0 0 1 0 0 0 1 1 0 0 1 0 1] [0 0 0 1 0 1 0 1 1 0 0 0 0 1]\n",
            "0.8000000000000002\n",
            "  Accuracy: 0.67\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 3 / 10 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:249: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    40  of     80.    Elapsed: 0:00:27    LR . 7.98E-06\n",
            "\n",
            "  Average training loss: 0.44\n",
            "  Training epcoh took: 0:00:54\n",
            "\n",
            "Running Validation...\n",
            "[0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 1] [0 0 0 1 1 1 0 1 1 0 1 0 1 1 0 1]\n",
            "0.46153846153846156\n",
            "[1 0 1 0 1 0 0 1 0 0 0 1 1 1 1 0] [0 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0]\n",
            "0.5\n",
            "[1 1 0 0 0 1 0 1 1 1 0 0 1 1 1 1] [0 1 0 0 0 1 0 1 1 0 0 0 1 1 1 0]\n",
            "0.8235294117647058\n",
            "[0 0 1 1 1 0 0 1 0 0 1 0 1 1 1 1] [0 0 1 1 1 0 0 1 0 1 1 0 1 1 0 1]\n",
            "0.8888888888888888\n",
            "[0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0] [0 1 1 0 0 1 0 0 0 0 1 0 1 1 1 1]\n",
            "0.5454545454545454\n",
            "[1 0 1 1 1 1 0 1 0 1 0 0 0 0 0 0] [1 0 1 0 1 1 1 1 0 1 0 0 0 0 0 0]\n",
            "0.8571428571428571\n",
            "[0 0 1 0 0 0 1 0 1 0 1 1 1 0 1 0] [0 0 0 0 1 0 1 0 1 0 1 1 1 0 1 0]\n",
            "0.8571428571428571\n",
            "[0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0] [0 0 0 1 1 1 0 1 0 0 0 0 1 0 0 1]\n",
            "0.8\n",
            "[0 0 0 0 0 0 0 1 1 0 0 1 0 1] [0 0 0 1 0 1 0 1 1 0 0 0 0 1]\n",
            "0.6666666666666665\n",
            "  Accuracy: 0.71\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 4 / 10 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:249: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    40  of     80.    Elapsed: 0:00:27    LR . 6.91E-06\n",
            "\n",
            "  Average training loss: 0.30\n",
            "  Training epcoh took: 0:00:54\n",
            "\n",
            "Running Validation...\n",
            "[0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1] [0 0 0 1 1 1 0 1 1 0 1 0 1 1 0 1]\n",
            "0.5\n",
            "[0 0 1 0 1 0 0 1 0 0 0 0 1 1 1 0] [0 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0]\n",
            "0.6\n",
            "[1 1 0 0 0 1 0 0 1 1 0 0 1 1 1 0] [0 1 0 0 0 1 0 1 1 0 0 0 1 1 1 0]\n",
            "0.7999999999999999\n",
            "[0 0 1 1 1 0 0 0 0 0 1 0 1 1 1 1] [0 0 1 1 1 0 0 1 0 1 1 0 1 1 0 1]\n",
            "0.823529411764706\n",
            "[0 1 1 0 0 0 0 0 0 0 0 0 1 0 1 0] [0 1 1 0 0 1 0 0 0 0 1 0 1 1 1 1]\n",
            "0.6666666666666666\n",
            "[1 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0] [1 0 1 0 1 1 1 1 0 1 0 0 0 0 0 0]\n",
            "0.8333333333333333\n",
            "[0 0 1 0 0 0 1 0 1 0 1 1 1 0 1 0] [0 0 0 0 1 0 1 0 1 0 1 1 1 0 1 0]\n",
            "0.8571428571428571\n",
            "[0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0] [0 0 0 1 1 1 0 1 0 0 0 0 1 0 0 1]\n",
            "0.8\n",
            "[0 0 0 0 0 0 0 1 1 0 1 1 0 1] [0 0 0 1 0 1 0 1 1 0 0 0 0 1]\n",
            "0.6\n",
            "  Accuracy: 0.72\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 5 / 10 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-0206f69d1d4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m               \u001b[0;31m# Perform a backward pass to calculate the gradients.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m               \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m               \u001b[0;31m# Clip the norm of the gradients to 1.0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "final_list = []\n",
        "\n",
        "for ran in random_list:\n",
        "    random_state = ran\n",
        "    kf = StratifiedKFold(n_splits=10, random_state=random_state, shuffle=True)\n",
        "    f1_list=[]\n",
        "    for i,(train_index, validation_index) in enumerate(kf.split(input_ids,y)):\n",
        "      z=i\n",
        "      # if i==2:\n",
        "      #   break\n",
        "      print()\n",
        "      print(\"---------------------------------FOLD NO: \", i)\n",
        "      # print(train_index, validation_index)\n",
        "      train_inputs = list(itemgetter(*train_index)(input_ids))\n",
        "      train_labels = list(itemgetter(*train_index)(labels))\n",
        "      train_masks = list(itemgetter(*train_index)(attention_masks))\n",
        "\n",
        "      validation_inputs = list(itemgetter(*validation_index)(input_ids))\n",
        "      validation_labels = list(itemgetter(*validation_index)(labels))\n",
        "      validation_masks = list(itemgetter(*validation_index)(attention_masks))\n",
        "\n",
        "      train_inputs = torch.tensor(train_inputs)\n",
        "      validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "      train_labels = torch.tensor(train_labels)\n",
        "      validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "      train_masks = torch.tensor(train_masks)\n",
        "      validation_masks = torch.tensor(validation_masks)\n",
        "\n",
        "      \n",
        "      train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "      train_sampler = RandomSampler(train_data)\n",
        "      train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "      \n",
        "      validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "      validation_sampler = SequentialSampler(validation_data)\n",
        "      validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
        "\n",
        "      model = AutoModelForSequenceClassification.from_pretrained(model_name) \n",
        "      tokenizer = AutoTokenizer.from_pretrained(model_name, do_lower_case=False)\n",
        "\n",
        "      model.cuda();\n",
        "      optimizer = AdamW(model.parameters(),\n",
        "                        lr = learning_rate, \n",
        "                        eps = 1e-8 \n",
        "                      )\n",
        "\n",
        "\n",
        "      \n",
        "      print('len(train_dataloader)', len(train_dataloader))\n",
        "      total_steps = len(train_dataloader) * epochs\n",
        "      print('total_steps', total_steps)\n",
        "      warmup_steps = int(0.06 * total_steps)\n",
        "      print('warmup_steps', warmup_steps)\n",
        "     \n",
        "      scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                                  num_warmup_steps = warmup_steps, # Default value in run_glue.py\n",
        "                                                  num_training_steps = total_steps)\n",
        "\n",
        "     \n",
        "      loss_values = []\n",
        "\n",
        "      \n",
        "      for epoch_i in range(0, epochs):\n",
        "\n",
        "          # ========================================\n",
        "          #               Training\n",
        "          # ========================================\n",
        "\n",
        "          \n",
        "\n",
        "          print(\"\")\n",
        "          print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "          print('Training...')\n",
        "\n",
        "          \n",
        "          t0 = time.time()\n",
        "\n",
        "          \n",
        "          total_loss = 0\n",
        "\n",
        "          \n",
        "          model.train()\n",
        "\n",
        "          \n",
        "          for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "            \n",
        "              if step % 40 == 0 and not step == 0:\n",
        "                  \n",
        "                  elapsed = format_time(time.time() - t0)\n",
        "\n",
        "                 \n",
        "                  print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}    LR . {:.2E}'.format(step, len(train_dataloader), elapsed, scheduler.get_lr()[0]))\n",
        "\n",
        "           \n",
        "              b_input_ids = batch[0].to(device)\n",
        "              b_input_mask = batch[1].to(device)\n",
        "              b_labels = batch[2].to(device)\n",
        "               \n",
        "              model.zero_grad()        \n",
        "\n",
        "              outputs = model(b_input_ids, \n",
        "                          attention_mask=b_input_mask, \n",
        "                          labels=b_labels)\n",
        "\n",
        "              \n",
        "              loss = outputs[0]\n",
        "\n",
        "              total_loss += loss.item()\n",
        "\n",
        "              loss.backward()\n",
        "\n",
        "              torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "              optimizer.step()\n",
        "\n",
        "              scheduler.step()\n",
        "\n",
        "          avg_train_loss = total_loss / len(train_dataloader)            \n",
        "\n",
        "          loss_values.append(avg_train_loss)\n",
        "\n",
        "          print(\"\")\n",
        "          print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "          print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "          # ========================================\n",
        "          #               Validation\n",
        "          # ========================================\n",
        "         \n",
        "\n",
        "          print(\"\")\n",
        "          print(\"Running Validation...\")\n",
        "\n",
        "          t0 = time.time()\n",
        "\n",
        "          model.eval()\n",
        "          eval_loss, eval_accuracy = 0, 0\n",
        "          nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "          for batch in validation_dataloader:\n",
        "\n",
        "              batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "              b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "              with torch.no_grad():        \n",
        "\n",
        "                  outputs = model(b_input_ids, \n",
        "                                  attention_mask=b_input_mask)\n",
        "\n",
        "              logits = outputs[0]\n",
        "\n",
        "              logits = logits.detach().cpu().numpy()\n",
        "              label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "              tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "              print(tmp_eval_accuracy)\n",
        "\n",
        "              eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "              nb_eval_steps += 1\n",
        "\n",
        "          print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "          print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "      print(\"\")\n",
        "      print(\"Training complete!\")\n",
        "\n",
        "      print('Predicting labels for {:,} dev sentences...'.format(len(validation_inputs)))\n",
        "\n",
        "      model.eval()\n",
        "\n",
        "      predictions , true_labels = [], []\n",
        "\n",
        "      for batch in validation_dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(b_input_ids, \n",
        "                            attention_mask=b_input_mask)\n",
        "\n",
        "        logits = outputs[0]\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        predictions.append(logits)\n",
        "        true_labels.append(label_ids)\n",
        "\n",
        "      print('    DONE.')\n",
        "      pred_list=[]\n",
        "      true_list=[]\n",
        "      for i in range(len(true_labels)):\n",
        "        pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "        pred_list.extend(list(pred_labels_i))\n",
        "        true_list.extend(list(true_labels[i]))\n",
        "\n",
        "      from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay, precision_score, recall_score, f1_score, fbeta_score\n",
        "\n",
        "      print(\"---------------------------------Confusion Matrix------------------------------------\")\n",
        "      final_create_confusion_matrix = confusion_matrix(true_list, pred_list)\n",
        "      final_confusion_matrix_df = pd.DataFrame(final_create_confusion_matrix)\n",
        "      display(final_confusion_matrix_df)\n",
        "      # Precision, Recall and F1 score calculation\n",
        "      final_eval_metrics = classification_report(true_list, pred_list, output_dict=True)\n",
        "\n",
        "      # computing other f-beta scores\n",
        "      f_0_5_micro = fbeta_score(true_list, pred_list, beta = 0.5, average = 'micro')\n",
        "      f_0_5_macro = fbeta_score(true_list, pred_list, beta = 0.5, average = 'macro')\n",
        "      f_0_5_weighted = fbeta_score(true_list, pred_list, beta = 0.5, average = 'weighted')\n",
        "\n",
        "      f_1_micro = fbeta_score(true_list, pred_list, beta = 1, average = 'micro')\n",
        "      f_1_macro = fbeta_score(true_list, pred_list, beta = 1, average = 'macro')\n",
        "      f_1_weighted = fbeta_score(true_list, pred_list, beta = 1, average = 'weighted')\n",
        "\n",
        "      f_2_micro = fbeta_score(true_list, pred_list, beta = 2, average = 'micro')\n",
        "      f_2_macro = fbeta_score(true_list, pred_list, beta = 2, average = 'macro')\n",
        "      f_2_weighted = fbeta_score(true_list, pred_list, beta = 2, average = 'weighted')\n",
        "\n",
        "      print(\"---------------------------------Evaluation Metrics------------------------------------\")\n",
        "      final_eval_metrics_df = pd.DataFrame(final_eval_metrics).transpose()\n",
        "      final_eval_metrics_df = final_eval_metrics_df.iloc[: , :-1]\n",
        "      display(final_eval_metrics_df)\n",
        "      # F-beta scores dataframe\n",
        "      data = {'F1-score':[f_1_micro, f_1_macro, f_1_weighted],\n",
        "              'F0.5-score':[f_0_5_micro, f_0_5_macro, f_0_5_weighted],\n",
        "              'F2-score':[f_2_micro, f_2_macro, f_2_weighted]}\n",
        "      f_beta_df = pd.DataFrame(data, index =['Micro-Average','Macro-Average','Weighted-Average'])\n",
        "      display(f_beta_df)\n",
        "      print(\"---------------------------------Normalized Matrix------------------------------------\")\n",
        "\n",
        "      f1_list.append(final_eval_metrics)\n",
        " \n",
        "    final_list.extend(f1_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "DgyjfktYDjiu"
      },
      "outputs": [],
      "source": [
        "p = []\n",
        "r = []\n",
        "f1 = []\n",
        "for f in final_list:\n",
        "    p.append(f[\"1\"][\"precision\"])\n",
        "    r.append(f[\"1\"][\"recall\"])\n",
        "    f1.append(f[\"1\"][\"f1-score\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BY961tmDjiv",
        "outputId": "0a4479f4-63dd-4e60-ce2a-d29b6b95db43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metaphor results\n",
            "\n",
            "Precision 0.7954908858330669\n",
            "Recall 0.7122375832053252\n",
            "F1 score 0.7508549444286121\n",
            "Std Dev 0.013400570233373018\n"
          ]
        }
      ],
      "source": [
        "print(task_name + \" results\")\n",
        "print()\n",
        "print(\"Precision\",mean(p))\n",
        "print(\"Recall\",mean(r))\n",
        "print(\"F1 score\",mean(f1))\n",
        "print(\"Std Dev\",stdev(f1))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the following cell to obtain prediction files and models for 10-fold cross validation (single run)"
      ],
      "metadata": {
        "id": "LPe7-v3trWUK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kf = StratifiedKFold(n_splits=10, random_state=random_st, shuffle=True)\n",
        "f1_list=[]\n",
        "for i,(train_index, validation_index) in enumerate(kf.split(input_ids,y)):\n",
        "  z=i\n",
        "  if i==1:\n",
        "    break\n",
        "  print()\n",
        "  print(\"---------------------------------FOLD NO: \", i)\n",
        "\n",
        "  train_inputs = list(itemgetter(*train_index)(input_ids))\n",
        "  train_labels = list(itemgetter(*train_index)(labels))\n",
        "  train_masks = list(itemgetter(*train_index)(attention_masks))\n",
        "\n",
        "  validation_inputs = list(itemgetter(*validation_index)(input_ids))\n",
        "  validation_labels = list(itemgetter(*validation_index)(labels))\n",
        "  validation_masks = list(itemgetter(*validation_index)(attention_masks))\n",
        "\n",
        "\n",
        "  train_inputs = torch.tensor(train_inputs)\n",
        "  validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "  train_labels = torch.tensor(train_labels)\n",
        "  validation_labels = torch.tensor(validation_labels)\n",
        "  \n",
        "  train_masks = torch.tensor(train_masks)\n",
        "  validation_masks = torch.tensor(validation_masks)\n",
        "\n",
        "\n",
        "  train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "  train_sampler = RandomSampler(train_data)\n",
        "  train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "  validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "  validation_sampler = SequentialSampler(validation_data)\n",
        "  validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
        "\n",
        "  model = AutoModelForSequenceClassification.from_pretrained(model_name) \n",
        "  tokenizer = AutoTokenizer.from_pretrained(model_name, do_lower_case=False)\n",
        "\n",
        "  model.cuda();\n",
        "  optimizer = AdamW(model.parameters(),\n",
        "                    lr = learning_rate, \n",
        "                    eps = 1e-8 \n",
        "                  )\n",
        "\n",
        "  \n",
        "  print('len(train_dataloader)', len(train_dataloader))\n",
        "  total_steps = len(train_dataloader) * epochs\n",
        "  print('total_steps', total_steps)\n",
        "  warmup_steps = int(0.06 * total_steps)\n",
        "  print('warmup_steps', warmup_steps)\n",
        "\n",
        "  scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                              num_warmup_steps = warmup_steps,\n",
        "                                              num_training_steps = total_steps)\n",
        "  \n",
        "  \n",
        "  loss_values = []\n",
        "\n",
        "  for epoch_i in range(0, epochs):\n",
        "      \n",
        "      # ========================================\n",
        "      #               Training\n",
        "      # ========================================\n",
        "      \n",
        "      \n",
        "\n",
        "      print(\"\")\n",
        "      print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "      print('Training...')\n",
        "\n",
        "      t0 = time.time()\n",
        "\n",
        "      total_loss = 0\n",
        "\n",
        "      model.train()\n",
        "\n",
        "      for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "          if step % 40 == 0 and not step == 0:\n",
        "             \n",
        "              elapsed = format_time(time.time() - t0)\n",
        "              \n",
        "             \n",
        "              print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}    LR . {:.2E}'.format(step, len(train_dataloader), elapsed, scheduler.get_lr()[0]))\n",
        "\n",
        "          b_input_ids = batch[0].to(device)\n",
        "          b_input_mask = batch[1].to(device)\n",
        "          b_labels = batch[2].to(device)\n",
        "\n",
        "          model.zero_grad()        \n",
        "\n",
        "          outputs = model(b_input_ids, \n",
        "                      attention_mask=b_input_mask, \n",
        "                      labels=b_labels)\n",
        "          \n",
        "          loss = outputs[0]\n",
        "          total_loss += loss.item()\n",
        "\n",
        "          loss.backward()\n",
        "\n",
        "          torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "          optimizer.step()\n",
        "\n",
        "          scheduler.step()\n",
        "\n",
        "      avg_train_loss = total_loss / len(train_dataloader)            \n",
        "      \n",
        "      loss_values.append(avg_train_loss)\n",
        "\n",
        "      print(\"\")\n",
        "      print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "      print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "          \n",
        "      # ========================================\n",
        "      #               Validation\n",
        "      # ========================================\n",
        "      \n",
        "\n",
        "      print(\"\")\n",
        "      print(\"Running Validation...\")\n",
        "\n",
        "      t0 = time.time()\n",
        "      model.eval()\n",
        "\n",
        "      eval_loss, eval_accuracy = 0, 0\n",
        "      nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "      for batch in validation_dataloader:\n",
        "          \n",
        "          batch = tuple(t.to(device) for t in batch)\n",
        "          b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "          with torch.no_grad():        \n",
        "              outputs = model(b_input_ids, \n",
        "                              attention_mask=b_input_mask)\n",
        "          \n",
        "          logits = outputs[0]\n",
        "\n",
        "          logits = logits.detach().cpu().numpy()\n",
        "          label_ids = b_labels.to('cpu').numpy()\n",
        "          \n",
        "          tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "          print(tmp_eval_accuracy)\n",
        "          \n",
        "          eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "          nb_eval_steps += 1\n",
        "\n",
        "      print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "      print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"Training complete!\")\n",
        "\n",
        "  print('Predicting labels for {:,} dev sentences...'.format(len(validation_inputs)))\n",
        "\n",
        "  model.eval()\n",
        "  predictions , true_labels = [], []\n",
        "\n",
        "  for batch in validation_dataloader:\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        outputs = model(b_input_ids, \n",
        "                        attention_mask=b_input_mask)\n",
        "\n",
        "    logits = outputs[0]\n",
        "\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    \n",
        "    predictions.append(logits)\n",
        "    true_labels.append(label_ids)\n",
        "\n",
        "  print('    DONE.')\n",
        "  pred_list=[]\n",
        "  true_list=[]\n",
        "  for i in range(len(true_labels)):\n",
        "    pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "    pred_list.extend(list(pred_labels_i))\n",
        "    true_list.extend(list(true_labels[i]))\n",
        "\n",
        "  from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay, precision_score, recall_score, f1_score, fbeta_score\n",
        "  # Consolidated evaluation metrics\n",
        "  print(\"---------------------------------Confusion Matrix------------------------------------\")\n",
        "  final_create_confusion_matrix = confusion_matrix(true_list, pred_list)\n",
        "  final_confusion_matrix_df = pd.DataFrame(final_create_confusion_matrix)\n",
        "  display(final_confusion_matrix_df)\n",
        "  # Precision, Recall and F1 score calculation\n",
        "  final_eval_metrics = classification_report(true_list, pred_list, output_dict=True)\n",
        "\n",
        "  # computing other f-beta scores\n",
        "  f_0_5_micro = fbeta_score(true_list, pred_list, beta = 0.5, average = 'micro')\n",
        "  f_0_5_macro = fbeta_score(true_list, pred_list, beta = 0.5, average = 'macro')\n",
        "  f_0_5_weighted = fbeta_score(true_list, pred_list, beta = 0.5, average = 'weighted')\n",
        "\n",
        "  f_1_micro = fbeta_score(true_list, pred_list, beta = 1, average = 'micro')\n",
        "  f_1_macro = fbeta_score(true_list, pred_list, beta = 1, average = 'macro')\n",
        "  f_1_weighted = fbeta_score(true_list, pred_list, beta = 1, average = 'weighted')\n",
        "\n",
        "  f_2_micro = fbeta_score(true_list, pred_list, beta = 2, average = 'micro')\n",
        "  f_2_macro = fbeta_score(true_list, pred_list, beta = 2, average = 'macro')\n",
        "  f_2_weighted = fbeta_score(true_list, pred_list, beta = 2, average = 'weighted')\n",
        "\n",
        "  print(\"---------------------------------Evaluation Metrics------------------------------------\")\n",
        "  final_eval_metrics_df = pd.DataFrame(final_eval_metrics).transpose()\n",
        "  final_eval_metrics_df = final_eval_metrics_df.iloc[: , :-1]\n",
        "  display(final_eval_metrics_df)\n",
        "  # F-beta scores dataframe\n",
        "  data = {'F1-score':[f_1_micro, f_1_macro, f_1_weighted],\n",
        "          'F0.5-score':[f_0_5_micro, f_0_5_macro, f_0_5_weighted],\n",
        "          'F2-score':[f_2_micro, f_2_macro, f_2_weighted]}\n",
        "  f_beta_df = pd.DataFrame(data, index =['Micro-Average','Macro-Average','Weighted-Average'])\n",
        "  display(f_beta_df)\n",
        "  print(\"---------------------------------Normalized Matrix------------------------------------\")\n",
        "\n",
        "  f1_list.append(final_eval_metrics)\n",
        "\n",
        "  path_name = dataset_name + \"/stl/\" + task_name +\"/\" + str(random_st)\n",
        "  file_path = path_name + \"/predictions\"+str(z)+ \".csv\"\n",
        "  model_path = path_name + \"/model\" + str(z)\n",
        "\n",
        "  if not os.path.exists(path_name):\n",
        "    os.makedirs(path_name)\n",
        "  \n",
        "  val_sent = list(itemgetter(*validation_index)(df.sentence.values))\n",
        "\n",
        "  pred_df = pd.DataFrame(list(zip(val_sent, true_list, pred_list)), columns=[\"sentence\",\"true_label\",\"pred_label\"])\n",
        "  pred_df.to_csv(file_path)\n",
        "  model.save_pretrained(model_path) \n",
        "\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "t51xCTIqq9er",
        "outputId": "6c4888c2-920d-4faa-fedf-930531d71b14"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---------------------------------FOLD NO:  0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-large-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.23.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/pytorch_model.bin\n",
            "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-large-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.23.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/vocab.txt\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/tokenizer_config.json\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-large-uncased/snapshots/3835a195d41f7ddc47d5ecab84b64f71d6f144e9/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-large-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.23.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(train_dataloader) 80\n",
            "total_steps 800\n",
            "warmup_steps 48\n",
            "\n",
            "======== Epoch 1 / 10 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:249: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    40  of     80.    Elapsed: 0:00:28    LR . 8.33E-06\n",
            "\n",
            "  Average training loss: 0.76\n",
            "  Training epcoh took: 0:00:55\n",
            "\n",
            "Running Validation...\n",
            "[1 0 0 1 1 0 0 0 0 1 1 1 0 1 1 0] [0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0]\n",
            "0.5\n",
            "[0 1 0 0 0 1 0 0 0 1 0 1 1 0 1 1] [1 1 1 0 1 1 0 0 0 1 0 1 1 1 0 0]\n",
            "0.6250000000000001\n",
            "[1 0 1 0 1 0 1 1 1 0 0 1 1 0 1 0] [1 1 1 0 1 0 1 0 1 0 0 0 1 0 1 1]\n",
            "0.7777777777777778\n",
            "[0 1 0 1 1 1 0 0 1 1 1 0 0 0 1 0] [1 1 1 1 0 0 1 1 0 1 1 0 0 0 0 0]\n",
            "0.5\n",
            "[1 0 1 1 0 1 1 1 0 1 0 1 1 1 1 0] [1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0]\n",
            "0.5333333333333333\n",
            "[0 1 0 1 0 0 0 1 0 1 0 0 0 1 0 1] [1 1 0 0 1 0 0 1 0 0 0 1 0 1 1 1]\n",
            "0.5714285714285715\n",
            "[0 1 1 1 0 1 1 0 0 0 0 0 1 0 0 0] [1 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0]\n",
            "0.5\n",
            "[0 1 1 1 1 0 0 0 1 1 1 0 1 1 0 0] [0 1 1 1 0 0 0 1 0 1 1 1 1 1 0 0]\n",
            "0.7777777777777778\n",
            "[1 1 0 0 0 1 1 0 0 0 0 0 1 0] [1 1 0 0 0 1 1 0 0 1 0 0 0 0]\n",
            "0.8000000000000002\n",
            "  Accuracy: 0.62\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 2 / 10 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:249: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    40  of     80.    Elapsed: 0:00:27    LR . 9.04E-06\n",
            "\n",
            "  Average training loss: 0.57\n",
            "  Training epcoh took: 0:00:54\n",
            "\n",
            "Running Validation...\n",
            "[1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0] [0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0]\n",
            "0.4\n",
            "[1 1 0 1 0 1 1 0 0 1 0 1 1 0 1 0] [1 1 1 0 1 1 0 0 0 1 0 1 1 1 0 0]\n",
            "0.6666666666666666\n",
            "[1 1 1 0 1 0 1 1 1 0 1 1 1 0 0 0] [1 1 1 0 1 0 1 0 1 0 0 0 1 0 1 1]\n",
            "0.7368421052631577\n",
            "[1 0 0 1 1 1 0 0 1 1 1 0 0 0 0 0] [1 1 1 1 0 0 1 1 0 1 1 0 0 0 0 0]\n",
            "0.5333333333333333\n",
            "[1 1 1 0 0 0 0 1 0 1 0 1 1 1 1 1] [1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0]\n",
            "0.5714285714285715\n",
            "[0 1 0 1 0 0 1 1 0 0 0 1 0 1 1 1] [1 1 0 0 1 0 0 1 0 0 0 1 0 1 1 1]\n",
            "0.75\n",
            "[0 1 1 1 0 1 0 1 0 0 1 0 1 0 0 0] [1 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0]\n",
            "0.6153846153846153\n",
            "[0 1 1 1 1 0 0 0 1 1 1 1 1 1 0 0] [0 1 1 1 0 0 0 1 0 1 1 1 1 1 0 0]\n",
            "0.8421052631578948\n",
            "[1 1 0 0 0 1 1 0 0 0 0 0 0 1] [1 1 0 0 0 1 1 0 0 1 0 0 0 0]\n",
            "0.8000000000000002\n",
            "  Accuracy: 0.66\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 3 / 10 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:249: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    40  of     80.    Elapsed: 0:00:27    LR . 7.98E-06\n",
            "\n",
            "  Average training loss: 0.50\n",
            "  Training epcoh took: 0:00:54\n",
            "\n",
            "Running Validation...\n",
            "[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0] [0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0]\n",
            "0.4444444444444445\n",
            "[1 1 0 1 0 1 1 0 0 1 0 1 1 0 1 0] [1 1 1 0 1 1 0 0 0 1 0 1 1 1 0 0]\n",
            "0.6666666666666666\n",
            "[1 1 1 0 1 0 1 1 1 0 1 1 1 0 0 0] [1 1 1 0 1 0 1 0 1 0 0 0 1 0 1 1]\n",
            "0.7368421052631577\n",
            "[1 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0] [1 1 1 1 0 0 1 1 0 1 1 0 0 0 0 0]\n",
            "0.5714285714285715\n",
            "[1 0 1 0 0 0 0 1 0 1 0 1 1 1 1 0] [1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0]\n",
            "0.6666666666666666\n",
            "[0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1] [1 1 0 0 1 0 0 1 0 0 0 1 0 1 1 1]\n",
            "0.6666666666666666\n",
            "[0 1 1 0 0 1 0 1 0 0 0 0 1 0 0 0] [1 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0]\n",
            "0.5454545454545454\n",
            "[0 0 1 1 0 0 0 1 1 1 1 1 1 1 0 0] [0 1 1 1 0 0 0 1 0 1 1 1 1 1 0 0]\n",
            "0.8888888888888888\n",
            "[1 1 0 0 0 1 0 0 0 0 0 0 1 1] [1 1 0 0 0 1 1 0 0 1 0 0 0 0]\n",
            "0.6\n",
            "  Accuracy: 0.64\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 4 / 10 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:249: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    40  of     80.    Elapsed: 0:00:27    LR . 6.91E-06\n",
            "\n",
            "  Average training loss: 0.36\n",
            "  Training epcoh took: 0:00:54\n",
            "\n",
            "Running Validation...\n",
            "[0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0] [0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0]\n",
            "0.5714285714285715\n",
            "[1 1 0 1 0 0 0 0 0 1 0 1 0 0 1 0] [1 1 1 0 1 1 0 0 0 1 0 1 1 1 0 0]\n",
            "0.5333333333333333\n",
            "[1 0 1 0 1 0 1 0 0 0 0 1 1 0 0 0] [1 1 1 0 1 0 1 0 1 0 0 0 1 0 1 1]\n",
            "0.6666666666666667\n",
            "[0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0] [1 1 1 1 0 0 1 1 0 1 1 0 0 0 0 0]\n",
            "0.5\n",
            "[1 0 1 0 0 0 0 1 0 1 0 1 1 1 1 0] [1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0]\n",
            "0.6666666666666666\n",
            "[0 1 0 0 0 0 1 1 0 0 0 0 0 0 1 0] [1 1 0 0 1 0 0 1 0 0 0 1 0 1 1 1]\n",
            "0.5\n",
            "[0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0] [1 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0]\n",
            "0.5454545454545454\n",
            "[0 0 1 1 0 0 0 1 0 0 1 1 1 1 0 0] [0 1 1 1 0 0 0 1 0 1 1 1 1 1 0 0]\n",
            "0.8750000000000001\n",
            "[1 1 0 0 0 1 0 0 0 0 0 0 1 1] [1 1 0 0 0 1 1 0 0 1 0 0 0 0]\n",
            "0.6\n",
            "  Accuracy: 0.61\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 5 / 10 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:249: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    40  of     80.    Elapsed: 0:00:27    LR . 5.85E-06\n",
            "\n",
            "  Average training loss: 0.25\n",
            "  Training epcoh took: 0:00:54\n",
            "\n",
            "Running Validation...\n",
            "[0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0] [0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0]\n",
            "0.5\n",
            "[1 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0] [1 1 1 0 1 1 0 0 0 1 0 1 1 1 0 0]\n",
            "0.5882352941176471\n",
            "[1 0 1 0 1 0 1 0 1 0 0 1 1 0 0 0] [1 1 1 0 1 0 1 0 1 0 0 0 1 0 1 1]\n",
            "0.75\n",
            "[1 1 0 1 1 1 0 0 0 1 1 0 0 0 0 0] [1 1 1 1 0 0 1 1 0 1 1 0 0 0 0 0]\n",
            "0.6666666666666666\n",
            "[1 0 1 0 0 0 0 1 0 1 0 1 1 1 1 0] [1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0]\n",
            "0.6666666666666666\n",
            "[0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 1] [1 1 0 0 1 0 0 1 0 0 0 1 0 1 1 1]\n",
            "0.7692307692307693\n",
            "[0 1 1 0 0 1 1 0 0 0 1 0 1 0 0 0] [1 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0]\n",
            "0.6666666666666666\n",
            "[0 1 1 1 0 0 0 1 0 1 1 1 1 1 0 0] [0 1 1 1 0 0 0 1 0 1 1 1 1 1 0 0]\n",
            "1.0\n",
            "[1 1 0 0 0 1 1 0 0 0 0 0 1 1] [1 1 0 0 0 1 1 0 0 1 0 0 0 0]\n",
            "0.7272727272727272\n",
            "  Accuracy: 0.70\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 6 / 10 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:249: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    40  of     80.    Elapsed: 0:00:27    LR . 4.79E-06\n",
            "\n",
            "  Average training loss: 0.18\n",
            "  Training epcoh took: 0:00:54\n",
            "\n",
            "Running Validation...\n",
            "[0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0] [0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0]\n",
            "0.5\n",
            "[1 1 1 1 0 1 1 0 0 1 0 1 1 0 1 0] [1 1 1 0 1 1 0 0 0 1 0 1 1 1 0 0]\n",
            "0.7368421052631577\n",
            "[1 1 1 0 1 0 1 0 1 0 0 1 1 0 1 1] [1 1 1 0 1 0 1 0 1 0 0 0 1 0 1 1]\n",
            "0.9473684210526316\n",
            "[1 1 0 1 1 1 0 0 0 0 1 0 0 0 0 0] [1 1 1 1 0 0 1 1 0 1 1 0 0 0 0 0]\n",
            "0.5714285714285715\n",
            "[1 0 1 0 0 0 0 1 0 1 0 1 1 1 1 0] [1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0]\n",
            "0.6666666666666666\n",
            "[0 1 0 0 0 0 1 1 0 0 0 1 0 0 1 0] [1 1 0 0 1 0 0 1 0 0 0 1 0 1 1 1]\n",
            "0.6153846153846154\n",
            "[0 1 1 1 0 1 1 0 0 0 1 0 1 0 0 0] [1 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0]\n",
            "0.6153846153846153\n",
            "[0 1 1 1 0 0 0 1 0 0 1 1 1 1 0 0] [0 1 1 1 0 0 0 1 0 1 1 1 1 1 0 0]\n",
            "0.9411764705882353\n",
            "[1 1 0 0 0 1 1 0 0 0 0 0 1 1] [1 1 0 0 0 1 1 0 0 1 0 0 0 0]\n",
            "0.7272727272727272\n",
            "  Accuracy: 0.70\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 7 / 10 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:249: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    40  of     80.    Elapsed: 0:00:27    LR . 3.72E-06\n",
            "\n",
            "  Average training loss: 0.14\n",
            "  Training epcoh took: 0:00:54\n",
            "\n",
            "Running Validation...\n",
            "[0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0] [0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0]\n",
            "0.5\n",
            "[1 1 1 1 0 1 1 0 0 1 0 1 1 0 1 0] [1 1 1 0 1 1 0 0 0 1 0 1 1 1 0 0]\n",
            "0.7368421052631577\n",
            "[1 0 1 0 1 0 1 0 1 0 0 1 1 0 1 1] [1 1 1 0 1 0 1 0 1 0 0 0 1 0 1 1]\n",
            "0.8888888888888888\n",
            "[0 1 0 1 1 1 0 0 0 0 1 0 0 0 0 0] [1 1 1 1 0 0 1 1 0 1 1 0 0 0 0 0]\n",
            "0.4615384615384615\n",
            "[1 0 1 0 0 0 0 1 0 1 0 1 1 1 1 0] [1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0]\n",
            "0.6666666666666666\n",
            "[0 1 0 0 0 0 1 1 0 0 0 0 0 0 1 0] [1 1 0 0 1 0 0 1 0 0 0 1 0 1 1 1]\n",
            "0.5\n",
            "[0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0] [1 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0]\n",
            "0.5454545454545454\n",
            "[0 1 1 1 0 0 0 1 0 0 1 1 1 1 0 0] [0 1 1 1 0 0 0 1 0 1 1 1 1 1 0 0]\n",
            "0.9411764705882353\n",
            "[1 1 0 0 0 1 1 0 0 0 0 0 1 1] [1 1 0 0 0 1 1 0 0 1 0 0 0 0]\n",
            "0.7272727272727272\n",
            "  Accuracy: 0.66\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 8 / 10 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:249: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    40  of     80.    Elapsed: 0:00:27    LR . 2.66E-06\n",
            "\n",
            "  Average training loss: 0.08\n",
            "  Training epcoh took: 0:00:54\n",
            "\n",
            "Running Validation...\n",
            "[0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0] [0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0]\n",
            "0.28571428571428575\n",
            "[1 1 1 1 0 1 1 0 0 1 0 1 1 0 1 0] [1 1 1 0 1 1 0 0 0 1 0 1 1 1 0 0]\n",
            "0.7368421052631577\n",
            "[1 0 1 0 1 0 1 0 1 0 0 1 1 0 1 1] [1 1 1 0 1 0 1 0 1 0 0 0 1 0 1 1]\n",
            "0.8888888888888888\n",
            "[1 1 0 1 1 1 0 0 0 1 1 0 0 0 0 0] [1 1 1 1 0 0 1 1 0 1 1 0 0 0 0 0]\n",
            "0.6666666666666666\n",
            "[1 0 1 0 0 0 0 1 0 1 0 1 0 0 1 0] [1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0]\n",
            "0.8\n",
            "[0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0] [1 1 0 0 1 0 0 1 0 0 0 1 0 1 1 1]\n",
            "0.5454545454545454\n",
            "[0 1 1 0 0 1 1 0 0 0 1 0 1 0 0 0] [1 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0]\n",
            "0.6666666666666666\n",
            "[0 0 1 1 0 0 0 1 0 0 1 1 1 1 0 0] [0 1 1 1 0 0 0 1 0 1 1 1 1 1 0 0]\n",
            "0.8750000000000001\n",
            "[1 1 0 0 0 1 1 0 0 0 0 0 1 1] [1 1 0 0 0 1 1 0 0 1 0 0 0 0]\n",
            "0.7272727272727272\n",
            "  Accuracy: 0.69\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 9 / 10 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:249: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    40  of     80.    Elapsed: 0:00:27    LR . 1.60E-06\n",
            "\n",
            "  Average training loss: 0.07\n",
            "  Training epcoh took: 0:00:54\n",
            "\n",
            "Running Validation...\n",
            "[0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0] [0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0]\n",
            "0.28571428571428575\n",
            "[1 1 1 1 0 1 1 0 0 1 0 1 1 0 1 0] [1 1 1 0 1 1 0 0 0 1 0 1 1 1 0 0]\n",
            "0.7368421052631577\n",
            "[1 1 1 0 1 0 1 0 1 0 0 1 1 0 1 1] [1 1 1 0 1 0 1 0 1 0 0 0 1 0 1 1]\n",
            "0.9473684210526316\n",
            "[1 1 0 1 1 1 0 0 0 1 1 0 0 0 0 0] [1 1 1 1 0 0 1 1 0 1 1 0 0 0 0 0]\n",
            "0.6666666666666666\n",
            "[1 0 1 0 0 0 0 1 0 1 0 1 1 0 1 0] [1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0]\n",
            "0.7272727272727273\n",
            "[0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1] [1 1 0 0 1 0 0 1 0 0 0 1 0 1 1 1]\n",
            "0.6666666666666666\n",
            "[0 1 1 0 0 1 1 0 0 0 1 0 1 0 0 0] [1 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0]\n",
            "0.6666666666666666\n",
            "[0 0 1 1 0 0 0 1 0 0 1 1 1 1 0 0] [0 1 1 1 0 0 0 1 0 1 1 1 1 1 0 0]\n",
            "0.8750000000000001\n",
            "[1 1 0 0 0 1 1 0 0 0 0 0 1 1] [1 1 0 0 0 1 1 0 0 1 0 0 0 0]\n",
            "0.7272727272727272\n",
            "  Accuracy: 0.70\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 10 / 10 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:249: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    40  of     80.    Elapsed: 0:00:27    LR . 5.32E-07\n",
            "\n",
            "  Average training loss: 0.06\n",
            "  Training epcoh took: 0:00:54\n",
            "\n",
            "Running Validation...\n",
            "[0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0] [0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0]\n",
            "0.28571428571428575\n",
            "[1 1 1 1 0 1 1 0 0 1 0 1 1 0 1 0] [1 1 1 0 1 1 0 0 0 1 0 1 1 1 0 0]\n",
            "0.7368421052631577\n",
            "[1 0 1 0 1 0 1 0 1 0 0 1 1 0 1 1] [1 1 1 0 1 0 1 0 1 0 0 0 1 0 1 1]\n",
            "0.8888888888888888\n",
            "[1 1 0 1 1 1 0 0 0 0 1 0 0 0 0 0] [1 1 1 1 0 0 1 1 0 1 1 0 0 0 0 0]\n",
            "0.5714285714285715\n",
            "[1 0 1 0 0 0 0 1 0 1 0 1 0 0 1 0] [1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0]\n",
            "0.8\n",
            "[0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1] [1 1 0 0 1 0 0 1 0 0 0 1 0 1 1 1]\n",
            "0.6666666666666666\n",
            "[0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0] [1 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0]\n",
            "0.5454545454545454\n",
            "[0 0 1 1 0 0 0 1 0 0 1 1 1 1 0 0] [0 1 1 1 0 0 0 1 0 1 1 1 1 1 0 0]\n",
            "0.8750000000000001\n",
            "[1 1 0 0 0 1 1 0 0 0 0 0 1 1] [1 1 0 0 0 1 1 0 0 1 0 0 0 0]\n",
            "0.7272727272727272\n",
            "  Accuracy: 0.68\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "Training complete!\n",
            "Predicting labels for 142 dev sentences...\n",
            "    DONE.\n",
            "---------------------------------Confusion Matrix------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    0   1\n",
              "0  66  14\n",
              "1  20  42"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-51c8125a-7fed-4d06-ba06-2021da34211c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>66</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-51c8125a-7fed-4d06-ba06-2021da34211c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-51c8125a-7fed-4d06-ba06-2021da34211c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-51c8125a-7fed-4d06-ba06-2021da34211c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------Evaluation Metrics------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "              precision    recall  f1-score\n",
              "0              0.767442  0.825000  0.795181\n",
              "1              0.750000  0.677419  0.711864\n",
              "accuracy       0.760563  0.760563  0.760563\n",
              "macro avg      0.758721  0.751210  0.753523\n",
              "weighted avg   0.759826  0.760563  0.758803"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-90c9183d-a171-4992-87c0-a3a2cbc1bdcd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1-score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.825000</td>\n",
              "      <td>0.795181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.677419</td>\n",
              "      <td>0.711864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>accuracy</th>\n",
              "      <td>0.760563</td>\n",
              "      <td>0.760563</td>\n",
              "      <td>0.760563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>macro avg</th>\n",
              "      <td>0.758721</td>\n",
              "      <td>0.751210</td>\n",
              "      <td>0.753523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weighted avg</th>\n",
              "      <td>0.759826</td>\n",
              "      <td>0.760563</td>\n",
              "      <td>0.758803</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-90c9183d-a171-4992-87c0-a3a2cbc1bdcd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-90c9183d-a171-4992-87c0-a3a2cbc1bdcd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-90c9183d-a171-4992-87c0-a3a2cbc1bdcd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                  F1-score  F0.5-score  F2-score\n",
              "Micro-Average     0.760563    0.760563  0.760563\n",
              "Macro-Average     0.753523    0.756284  0.751799\n",
              "Weighted-Average  0.758803    0.759075  0.759532"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e54dade6-7607-4b5f-bb53-83ff8cca240f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>F1-score</th>\n",
              "      <th>F0.5-score</th>\n",
              "      <th>F2-score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Micro-Average</th>\n",
              "      <td>0.760563</td>\n",
              "      <td>0.760563</td>\n",
              "      <td>0.760563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Macro-Average</th>\n",
              "      <td>0.753523</td>\n",
              "      <td>0.756284</td>\n",
              "      <td>0.751799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Weighted-Average</th>\n",
              "      <td>0.758803</td>\n",
              "      <td>0.759075</td>\n",
              "      <td>0.759532</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e54dade6-7607-4b5f-bb53-83ff8cca240f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e54dade6-7607-4b5f-bb53-83ff8cca240f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e54dade6-7607-4b5f-bb53-83ff8cca240f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------Normalized Matrix------------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-047937b9dc96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m   \u001b[0mval_sent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mvalidation_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m   \u001b[0mpred_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_sent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sentence\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"true_label\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"pred_label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5485\u001b[0m         ):\n\u001b[1;32m   5486\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'Sentence'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p = []\n",
        "r = []\n",
        "f1 = []\n",
        "for f in final_list:\n",
        "    p.append(f[\"1\"][\"precision\"])\n",
        "    r.append(f[\"1\"][\"recall\"])\n",
        "    f1.append(f[\"1\"][\"f1-score\"])"
      ],
      "metadata": {
        "id": "U0Kc_1z0sQen"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(task_name + \" results\")\n",
        "print()\n",
        "print(\"Precision\",mean(p))\n",
        "print(\"Recall\",mean(r))\n",
        "print(\"F1 score\",mean(f1))\n",
        "print(\"Std Dev\",stdev(f1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZRcDunuuLCW",
        "outputId": "3f3b288e-6377-4df7-a14d-98a1310d28fa"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metaphor results\n",
            "\n",
            "Precision 0.7954908858330669\n",
            "Recall 0.7122375832053252\n",
            "F1 score 0.7508549444286121\n",
            "Std Dev 0.013400570233373018\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference on example sentences and attention weights\n"
      ],
      "metadata": {
        "id": "D16NL19QwcZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"He went a thousand miles to be here.\"\n",
        "\n",
        "\n",
        "inputs = tokenizer.encode(input_text, return_tensors='pt')  # Tokenize input text\n",
        "model = AutoModelForSequenceClassification.from_pretrained(path_name + \"/model0\", output_attentions=True) \n",
        "model.cuda()\n",
        "outputs = model(inputs.to(device))  # Run model\n",
        "attention = outputs[-1]  # Retrieve attention from model outputs\n",
        "tokens = tokenizer.convert_ids_to_tokens(inputs[0])  # Convert input ids to token strings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roTeE4A-uPEe",
        "outputId": "c1aca5d3-3447-4e34-9196-f31521b47f62"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file new_combined/stl/Metaphor/42/model0/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"new_combined/stl/Metaphor/42/model0\",\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"output_attentions\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.23.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file new_combined/stl/Metaphor/42/model0/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
            "\n",
            "All the weights of BertForSequenceClassification were initialized from the model checkpoint at new_combined/stl/Metaphor/42/model0.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum = torch.zeros(len(tokens),len(tokens))\n",
        "for i in range(16):\n",
        "    if i==0:\n",
        "        sum=outputs[-1][-1][0][i]\n",
        "    sum = torch.add(sum,outputs[-1][-1][0][i])\n",
        "#     outputs[-1][-1][0][0]\n",
        "sum[0]/torch.sum(sum[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sd6bx9XubGa",
        "outputId": "d309eedd-ef03-4240-e699-48f24a6a12eb"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0878, 0.1198, 0.0918, 0.0807, 0.0860, 0.0721, 0.0658, 0.0996, 0.1134,\n",
              "        0.0698, 0.1131], device='cuda:0', grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_tokens=[]\n",
        "a = torch.mean(outputs[-1][-1][:,:,0,:],1)[0][1:-1]\n",
        "for t in tokens:\n",
        "    new_tokens.append(tokenizer.convert_tokens_to_string(t))\n",
        "inf_df = pd.DataFrame([(a/torch.sum(a)).tolist()], columns=new_tokens[1:-1])\n",
        "inf_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "uosUs26buc5K",
        "outputId": "dfd9287e-efa6-4d49-8d52-346a8a2870f1"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   [ U N K ]   w e n t         a  t h o u s a n d  m i l e s       t o  \\\n",
              "0   0.153238  0.116093  0.100741         0.108808   0.090103  0.080082   \n",
              "\n",
              "        b e   h e r e         .  \n",
              "0  0.121178  0.144854  0.084902  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2eb91ee8-8aa6-43da-bcd4-32528f7cd354\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>[ U N K ]</th>\n",
              "      <th>w e n t</th>\n",
              "      <th>a</th>\n",
              "      <th>t h o u s a n d</th>\n",
              "      <th>m i l e s</th>\n",
              "      <th>t o</th>\n",
              "      <th>b e</th>\n",
              "      <th>h e r e</th>\n",
              "      <th>.</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.153238</td>\n",
              "      <td>0.116093</td>\n",
              "      <td>0.100741</td>\n",
              "      <td>0.108808</td>\n",
              "      <td>0.090103</td>\n",
              "      <td>0.080082</td>\n",
              "      <td>0.121178</td>\n",
              "      <td>0.144854</td>\n",
              "      <td>0.084902</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2eb91ee8-8aa6-43da-bcd4-32528f7cd354')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2eb91ee8-8aa6-43da-bcd4-32528f7cd354 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2eb91ee8-8aa6-43da-bcd4-32528f7cd354');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(len(tokens), 1))\n",
        "sns.heatmap(inf_df,cmap=sns.cm.rocket_r, cbar=False, annot=True, yticklabels=False)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "gRkATSZ_u1Nn",
        "outputId": "d8d1d982-2e25-4312-82e3-8ab4eced3234"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 792x72 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NHThCFAHu3kb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cb478d734ab74ac7b5537befb46c9802": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0d0be20cf7984e5cb864c4c8d75e5b2d",
              "IPY_MODEL_71e516ac54b948ac8328ef5d9f63d9eb",
              "IPY_MODEL_fa9010a2fb964530be3cf88361ca0430"
            ],
            "layout": "IPY_MODEL_c112c82ccff748f98bf6d5c197188990"
          }
        },
        "0d0be20cf7984e5cb864c4c8d75e5b2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1713c61d5be64b239d6e47b36b6f9d26",
            "placeholder": "​",
            "style": "IPY_MODEL_8acbede6c3dc4d5dada8e8a914ffd827",
            "value": "Downloading: 100%"
          }
        },
        "71e516ac54b948ac8328ef5d9f63d9eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a1a73d051614cd3b41e33894f839bf9",
            "max": 571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_70ee218a208a47f0aec219eb806002c0",
            "value": 571
          }
        },
        "fa9010a2fb964530be3cf88361ca0430": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_610e9e17a8334307a78ea20ca7a5dea7",
            "placeholder": "​",
            "style": "IPY_MODEL_948f059d6d61471bb12e3dba6de295ae",
            "value": " 571/571 [00:00&lt;00:00, 6.44kB/s]"
          }
        },
        "c112c82ccff748f98bf6d5c197188990": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1713c61d5be64b239d6e47b36b6f9d26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8acbede6c3dc4d5dada8e8a914ffd827": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a1a73d051614cd3b41e33894f839bf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70ee218a208a47f0aec219eb806002c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "610e9e17a8334307a78ea20ca7a5dea7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "948f059d6d61471bb12e3dba6de295ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb0df7b4691a4fd4929db21c120dc5ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d4912c2250f14201b7d96f3b4065e0df",
              "IPY_MODEL_e5220b36f5f1463b929cc65425d3a1af",
              "IPY_MODEL_0e3a55188bd84a1883beed9ea65f90bf"
            ],
            "layout": "IPY_MODEL_f14b9e39cc354562918685b3670fe637"
          }
        },
        "d4912c2250f14201b7d96f3b4065e0df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6eccb71baf5c43a6b8c3a1623d0e1572",
            "placeholder": "​",
            "style": "IPY_MODEL_e7540b8537dc405b8ae5f1a58cd5ffe5",
            "value": "Downloading: 100%"
          }
        },
        "e5220b36f5f1463b929cc65425d3a1af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69f18004bf7b46a98a5cda8a53870550",
            "max": 1344997306,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bd225e1e947f4b8c9b4c239ac9b2af79",
            "value": 1344997306
          }
        },
        "0e3a55188bd84a1883beed9ea65f90bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57548dca7e9b4525b898a18159cd2254",
            "placeholder": "​",
            "style": "IPY_MODEL_0f96ca76911d494f85d67d21c2fb9a68",
            "value": " 1.34G/1.34G [00:49&lt;00:00, 24.3MB/s]"
          }
        },
        "f14b9e39cc354562918685b3670fe637": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6eccb71baf5c43a6b8c3a1623d0e1572": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7540b8537dc405b8ae5f1a58cd5ffe5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69f18004bf7b46a98a5cda8a53870550": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd225e1e947f4b8c9b4c239ac9b2af79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "57548dca7e9b4525b898a18159cd2254": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f96ca76911d494f85d67d21c2fb9a68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bbfbe1f9893945d19976e0bdba49ccd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2c807d8e594f42ba89c28d3f7e7b5338",
              "IPY_MODEL_9ccdf75666b749e49ae54fe4baf1d95a",
              "IPY_MODEL_ab4b52142eb1441ab4930cd096926fdc"
            ],
            "layout": "IPY_MODEL_17af86d7a7bb4420a935f6d4a6a9c6e3"
          }
        },
        "2c807d8e594f42ba89c28d3f7e7b5338": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb8f10c4268248dcaba50c10cdb5172f",
            "placeholder": "​",
            "style": "IPY_MODEL_cf18b4206bed4377aa883e8ef9969213",
            "value": "Downloading: 100%"
          }
        },
        "9ccdf75666b749e49ae54fe4baf1d95a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff60e59d740b42aa8ee0a76ce5927d2c",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4f80d4580f6545b58f4511ac3b3dd651",
            "value": 28
          }
        },
        "ab4b52142eb1441ab4930cd096926fdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffc81d1ff091430da41b29281b78658e",
            "placeholder": "​",
            "style": "IPY_MODEL_b7d394d56d2e4a438cf0ffe984dafa15",
            "value": " 28.0/28.0 [00:00&lt;00:00, 445B/s]"
          }
        },
        "17af86d7a7bb4420a935f6d4a6a9c6e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb8f10c4268248dcaba50c10cdb5172f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf18b4206bed4377aa883e8ef9969213": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff60e59d740b42aa8ee0a76ce5927d2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f80d4580f6545b58f4511ac3b3dd651": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ffc81d1ff091430da41b29281b78658e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7d394d56d2e4a438cf0ffe984dafa15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a74d869ef5842b7a7792c41931af320": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a8e7467fa12f489fb103ed32478d2981",
              "IPY_MODEL_df3364882f474637bf0dcfc2eb4ba088",
              "IPY_MODEL_05d70adf360146d89a55553e1725818c"
            ],
            "layout": "IPY_MODEL_1c6af161fa0242c995ce011227850094"
          }
        },
        "a8e7467fa12f489fb103ed32478d2981": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d7f524940f64ac1b0873b00492e364e",
            "placeholder": "​",
            "style": "IPY_MODEL_9ff0c3fd97a34feaa4735a032e41a22f",
            "value": "Downloading: 100%"
          }
        },
        "df3364882f474637bf0dcfc2eb4ba088": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee2996c09c36407a9be5e04f2231718e",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec68850195aa41dcaf25701d0a4eac20",
            "value": 231508
          }
        },
        "05d70adf360146d89a55553e1725818c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a66f015fe45447b2b8d6388786bddd8f",
            "placeholder": "​",
            "style": "IPY_MODEL_86c9a7a9d79d47a0ae2ca6f28e7c0837",
            "value": " 232k/232k [00:00&lt;00:00, 473kB/s]"
          }
        },
        "1c6af161fa0242c995ce011227850094": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d7f524940f64ac1b0873b00492e364e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ff0c3fd97a34feaa4735a032e41a22f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee2996c09c36407a9be5e04f2231718e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec68850195aa41dcaf25701d0a4eac20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a66f015fe45447b2b8d6388786bddd8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86c9a7a9d79d47a0ae2ca6f28e7c0837": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "951b94aa516a42629abac59d7c3d97a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_229d425427c14f529f4c99435c76f1bd",
              "IPY_MODEL_0e9ae4c84b3d4d4bb83f7881cc34c781",
              "IPY_MODEL_4bf09704a3f64ea691061255fe9c7a80"
            ],
            "layout": "IPY_MODEL_019e1600a0ef468aa93dc797f5624638"
          }
        },
        "229d425427c14f529f4c99435c76f1bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c93a0f5d02864555b1c313a914ed6f8d",
            "placeholder": "​",
            "style": "IPY_MODEL_72bf9aef5bf44e6f8fc542f9a5197026",
            "value": "Downloading: 100%"
          }
        },
        "0e9ae4c84b3d4d4bb83f7881cc34c781": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a203f8d23e324ec8aea2560a92cb43f3",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6b34664e2efa4a5dad36d390770e0ccb",
            "value": 466062
          }
        },
        "4bf09704a3f64ea691061255fe9c7a80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9190f1d5dc504640b72ab803a9817fce",
            "placeholder": "​",
            "style": "IPY_MODEL_eeaf3f9618664774be13decb46462ad9",
            "value": " 466k/466k [00:00&lt;00:00, 576kB/s]"
          }
        },
        "019e1600a0ef468aa93dc797f5624638": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c93a0f5d02864555b1c313a914ed6f8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72bf9aef5bf44e6f8fc542f9a5197026": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a203f8d23e324ec8aea2560a92cb43f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b34664e2efa4a5dad36d390770e0ccb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9190f1d5dc504640b72ab803a9817fce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eeaf3f9618664774be13decb46462ad9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}